{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "gpuType": "A100",
      "collapsed_sections": [
        "IFP6JcUKoXIi"
      ],
      "authorship_tag": "ABX9TyOrlX1nVWnhj4euMM1igWhR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lightwsrld/pytorch/blob/main/transformer_%EA%B5%AC%ED%98%84.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y torch torchvision torchaudio torchtext torchdata"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WBCnJwRSjQWU",
        "outputId": "d2084727-cdb3-4d7a-874c-89b0f439acb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: torch 1.13.1\n",
            "Uninstalling torch-1.13.1:\n",
            "  Successfully uninstalled torch-1.13.1\n",
            "Found existing installation: torchvision 0.14.1\n",
            "Uninstalling torchvision-0.14.1:\n",
            "  Successfully uninstalled torchvision-0.14.1\n",
            "Found existing installation: torchaudio 0.13.1\n",
            "Uninstalling torchaudio-0.13.1:\n",
            "  Successfully uninstalled torchaudio-0.13.1\n",
            "Found existing installation: torchtext 0.14.1\n",
            "Uninstalling torchtext-0.14.1:\n",
            "  Successfully uninstalled torchtext-0.14.1\n",
            "Found existing installation: torchdata 0.5.1\n",
            "Uninstalling torchdata-0.5.1:\n",
            "  Successfully uninstalled torchdata-0.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch==2.0.0 torchvision==0.15.1 torchaudio==2.0.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "59amufpLo4mV",
        "outputId": "326c0c10-6862-4841-d559-1a2693b21b47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch==2.0.0\n",
            "  Using cached torch-2.0.0-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\n",
            "Collecting torchvision==0.15.1\n",
            "  Using cached torchvision-0.15.1-cp310-cp310-manylinux1_x86_64.whl (6.0 MB)\n",
            "Collecting torchaudio==2.0.1\n",
            "  Using cached torchaudio-2.0.1-cp310-cp310-manylinux1_x86_64.whl (4.4 MB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (4.6.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (3.1.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (11.7.101)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (10.2.10.91)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (11.4.0.1)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (11.7.4.91)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (2.14.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (11.7.91)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (2.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision==0.15.1) (1.22.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision==0.15.1) (2.27.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision==0.15.1) (8.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0) (67.7.2)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0) (0.40.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.0) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.0) (16.0.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.0.0) (2.1.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.15.1) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.15.1) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.15.1) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.15.1) (3.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.0) (1.3.0)\n",
            "Installing collected packages: torch, torchvision, torchaudio\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.13.1\n",
            "    Uninstalling torch-1.13.1:\n",
            "      Successfully uninstalled torch-1.13.1\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.14.1\n",
            "    Uninstalling torchvision-0.14.1:\n",
            "      Successfully uninstalled torchvision-0.14.1\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 0.13.1\n",
            "    Uninstalling torchaudio-0.13.1:\n",
            "      Successfully uninstalled torchaudio-0.13.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "fastai 2.7.11 requires torch<1.14,>=1.7, but you have torch 2.0.0 which is incompatible.\n",
            "torchdata 0.5.1 requires torch==1.13.1, but you have torch 2.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed torch-2.0.0 torchaudio-2.0.1 torchvision-0.15.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "torch",
                  "torchvision"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchtext==0.6.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RQ10SmnAxb6v",
        "outputId": "3b0d8e60-8e0e-4e9e-8aff-3c0f7df128c7"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchtext==0.6.0\n",
            "  Downloading torchtext-0.6.0-py3-none-any.whl (64 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/64.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.2/64.2 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (4.65.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (2.27.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (2.0.1+cu118)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (1.22.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (1.16.0)\n",
            "Collecting sentencepiece (from torchtext==0.6.0)\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m65.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6.0) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6.0) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6.0) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6.0) (3.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->torchtext==0.6.0) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->torchtext==0.6.0) (16.0.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->torchtext==0.6.0) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->torchtext==0.6.0) (1.3.0)\n",
            "Installing collected packages: sentencepiece, torchtext\n",
            "  Attempting uninstall: torchtext\n",
            "    Found existing installation: torchtext 0.15.2\n",
            "    Uninstalling torchtext-0.15.2:\n",
            "      Successfully uninstalled torchtext-0.15.2\n",
            "Successfully installed sentencepiece-0.1.99 torchtext-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchtext\n",
        "\n",
        "print(f'torch version: {torch.__version__}')\n",
        "print(f'torchvision version: {torchvision.__version__}')\n",
        "print(f'torchtext version: {torchtext.__version__}')\n",
        "print(\"cuda version: {}\".format(torch.version.cuda))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ASuTrYPfjnqL",
        "outputId": "c8d59cc3-5f02-4181-9a04-f0cca86e0ce8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch version: 2.0.1+cu118\n",
            "torchvision version: 0.15.2+cu118\n",
            "torchtext version: 0.6.0\n",
            "cuda version: 11.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "SEED = 1234\n",
        "\n",
        "random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "metadata": {
        "id": "HG0NP1TJEnZK"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!python -m spacy download en_core_web_sm\n",
        "!python -m spacy download de_core_news_sm"
      ],
      "metadata": {
        "id": "JV1BTrgYuV6J"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "spacy_en = spacy.load(\"en_core_web_sm\") # 영어 토큰화(tokenization)\n",
        "spacy_de = spacy.load(\"de_core_news_sm\") # 독일어 토큰화(tokenization)"
      ],
      "metadata": {
        "id": "NuG7m_ifuWIM"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 간단히 토큰화(tokenization) 기능 써보기\n",
        "\n",
        "tokenized = spacy_en.tokenizer(\"I am a graduate student.\")\n",
        "\n",
        "for i, token in enumerate(tokenized):\n",
        "    print(f\"인덱스 {i}: {token.text}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XsQ0QBrMvAFl",
        "outputId": "2ac39e1f-c10b-47bd-f822-5a4353645f8c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "인덱스 0: I\n",
            "인덱스 1: am\n",
            "인덱스 2: a\n",
            "인덱스 3: graduate\n",
            "인덱스 4: student\n",
            "인덱스 5: .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 영어 및 독일어 토큰화 함수 정의\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "NtKsls7juy4M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_de(text):\n",
        "\n",
        "    return [tok.text for tok in spacy_de.tokenizer(text)]        # input 문장의 토큰화 이후에 순서를 뒤집음 -> (X)\n",
        "\n",
        "def tokenize_en(text):\n",
        "\n",
        "    return [tok.text for tok in spacy_en.tokenizer(text)]\n"
      ],
      "metadata": {
        "id": "sZV4nziLuz33"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PAD_WORD = '<blank>' # padding token\n",
        "UNK_WORD = '<unk>' # unknown token\n",
        "BOS_WORD = '<s>' # start token\n",
        "EOS_WORD = '</s>' # end token\n",
        "\n",
        "SRC = torchtext.data.Field(                                       # Field 함수는 데이터 타입과 이를 텐서로 변환할 지시사항과 함께 저장, 텐서로 표현될 수 있는 텍스트 타입을 처리하고\n",
        "                                                                    # 각 토큰을 숫자 인덱스로 맵핑하는 vocab 객체가 존재\n",
        "    tokenize = tokenize_de, lower=True,\n",
        "    pad_token=PAD_WORD, init_token=BOS_WORD, eos_token=EOS_WORD)\n",
        "\n",
        "TRG = torchtext.data.Field(\n",
        "    tokenize = tokenize_en, lower=True,\n",
        "    pad_token=PAD_WORD, init_token=BOS_WORD, eos_token=EOS_WORD)"
      ],
      "metadata": {
        "id": "_V6CFZvK_iUZ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchtext.legacy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3EKR_bZWgeZN",
        "outputId": "7dc2e003-097f-4a2c-be5e-2f2166c196f1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement torchtext.legacy (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for torchtext.legacy\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext.datasets import Multi30k\n",
        "train_data, valid_data, test_data = Multi30k.splits(exts = ('.de', '.en'),\n",
        "                                                    fields = (SRC, TRG))\n",
        "\n",
        "print(f\"Number of training examples: {len(train_data.examples)}\")\n",
        "print(f\"Number of validation examples: {len(valid_data.examples)}\")\n",
        "print(f\"Number of testing examples: {len(test_data.examples)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6djGI-0Xf8QV",
        "outputId": "a864f9ef-867b-4a86-980e-c446607481b6"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "downloading training.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training.tar.gz: 100%|██████████| 1.21M/1.21M [00:03<00:00, 380kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "downloading validation.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "validation.tar.gz: 100%|██████████| 46.3k/46.3k [00:00<00:00, 110kB/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "downloading mmt_task1_test2016.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "mmt_task1_test2016.tar.gz: 100%|██████████| 66.2k/66.2k [00:00<00:00, 106kB/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training examples: 29000\n",
            "Number of validation examples: 1014\n",
            "Number of testing examples: 1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(vars(train_data.examples[25])['src'])\n",
        "print(vars(train_data.examples[25])['trg'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EhSTD4a2DI7N",
        "outputId": "4c272e36-d1ef-4ce8-9cd2-703a8313dffa"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['eine', 'person', 'in', 'einem', 'blauen', 'mantel', 'steht', 'auf', 'einem', 'belebten', 'gehweg', 'und', 'betrachtet', 'ein', 'gemälde', 'einer', 'straßenszene', '.']\n",
            "['a', 'person', 'dressed', 'in', 'a', 'blue', 'coat', 'is', 'standing', 'in', 'on', 'a', 'busy', 'sidewalk', ',', 'studying', 'painting', 'of', 'a', 'street', 'scene', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 영어와 독어의 단어 사전을 생성 -> 언어 도메인이 다르기 때문에 각자 따로 만듦\n",
        "# 2개 이상 나온 단어들만 사용\n",
        "\n",
        "SRC.build_vocab(train_data, min_freq=2)\n",
        "TRG.build_vocab(train_data, min_freq=2)\n",
        "\n",
        "print(f\"len(SRC): {len(SRC.vocab)}\")\n",
        "print(f\"len(TRG): {len(TRG.vocab)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06lTdhHWgHgz",
        "outputId": "6e721e3d-29bc-4548-bad8-c9667db70bf1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "len(SRC): 7853\n",
            "len(TRG): 5893\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 현재 단어 집합의 단어와 맵핑된 고유한 정수를 출력\n",
        "\n",
        "TRG.vocab.stoi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gca_2s3J07HQ",
        "outputId": "1bcba997-719d-40e2-864c-23c306eb4058"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "defaultdict(<bound method Vocab._default_unk_index of <torchtext.vocab.Vocab object at 0x7f1c7b5fcaf0>>,\n",
              "            {'<unk>': 0,\n",
              "             '<blank>': 1,\n",
              "             '<s>': 2,\n",
              "             '</s>': 3,\n",
              "             'a': 4,\n",
              "             '.': 5,\n",
              "             'in': 6,\n",
              "             'the': 7,\n",
              "             'on': 8,\n",
              "             'man': 9,\n",
              "             'is': 10,\n",
              "             'and': 11,\n",
              "             'of': 12,\n",
              "             'with': 13,\n",
              "             'woman': 14,\n",
              "             ',': 15,\n",
              "             'two': 16,\n",
              "             'are': 17,\n",
              "             'to': 18,\n",
              "             'people': 19,\n",
              "             'at': 20,\n",
              "             'an': 21,\n",
              "             'wearing': 22,\n",
              "             'shirt': 23,\n",
              "             'young': 24,\n",
              "             'white': 25,\n",
              "             'black': 26,\n",
              "             'his': 27,\n",
              "             'while': 28,\n",
              "             'blue': 29,\n",
              "             'men': 30,\n",
              "             'red': 31,\n",
              "             'sitting': 32,\n",
              "             'girl': 33,\n",
              "             'boy': 34,\n",
              "             'dog': 35,\n",
              "             'standing': 36,\n",
              "             'playing': 37,\n",
              "             'group': 38,\n",
              "             'street': 39,\n",
              "             'down': 40,\n",
              "             'walking': 41,\n",
              "             '-': 42,\n",
              "             'front': 43,\n",
              "             'her': 44,\n",
              "             'holding': 45,\n",
              "             'one': 46,\n",
              "             'water': 47,\n",
              "             'three': 48,\n",
              "             'by': 49,\n",
              "             'women': 50,\n",
              "             'up': 51,\n",
              "             'green': 52,\n",
              "             'little': 53,\n",
              "             'for': 54,\n",
              "             'child': 55,\n",
              "             'looking': 56,\n",
              "             'outside': 57,\n",
              "             'as': 58,\n",
              "             'large': 59,\n",
              "             'through': 60,\n",
              "             'brown': 61,\n",
              "             'yellow': 62,\n",
              "             'children': 63,\n",
              "             'person': 64,\n",
              "             'from': 65,\n",
              "             'their': 66,\n",
              "             'hat': 67,\n",
              "             'ball': 68,\n",
              "             'into': 69,\n",
              "             'small': 70,\n",
              "             'next': 71,\n",
              "             'other': 72,\n",
              "             'dressed': 73,\n",
              "             'some': 74,\n",
              "             'out': 75,\n",
              "             'over': 76,\n",
              "             'building': 77,\n",
              "             'riding': 78,\n",
              "             'running': 79,\n",
              "             'near': 80,\n",
              "             'jacket': 81,\n",
              "             'another': 82,\n",
              "             'around': 83,\n",
              "             'sidewalk': 84,\n",
              "             'field': 85,\n",
              "             'orange': 86,\n",
              "             'crowd': 87,\n",
              "             'beach': 88,\n",
              "             'stands': 89,\n",
              "             'pink': 90,\n",
              "             'sits': 91,\n",
              "             'jumping': 92,\n",
              "             'behind': 93,\n",
              "             'table': 94,\n",
              "             'snow': 95,\n",
              "             'grass': 96,\n",
              "             'hair': 97,\n",
              "             'background': 98,\n",
              "             'bike': 99,\n",
              "             'stand': 100,\n",
              "             'city': 101,\n",
              "             \"'s\": 102,\n",
              "             'air': 103,\n",
              "             'girls': 104,\n",
              "             'player': 105,\n",
              "             'asian': 106,\n",
              "             'looks': 107,\n",
              "             'wall': 108,\n",
              "             'top': 109,\n",
              "             'four': 110,\n",
              "             'off': 111,\n",
              "             'dogs': 112,\n",
              "             'several': 113,\n",
              "             'that': 114,\n",
              "             'older': 115,\n",
              "             'camera': 116,\n",
              "             'dress': 117,\n",
              "             'park': 118,\n",
              "             'talking': 119,\n",
              "             'lady': 120,\n",
              "             'something': 121,\n",
              "             'blond': 122,\n",
              "             'soccer': 123,\n",
              "             'along': 124,\n",
              "             'walks': 125,\n",
              "             'guitar': 126,\n",
              "             'boys': 127,\n",
              "             'play': 128,\n",
              "             'together': 129,\n",
              "             'working': 130,\n",
              "             'food': 131,\n",
              "             'gray': 132,\n",
              "             'smiling': 133,\n",
              "             'picture': 134,\n",
              "             'game': 135,\n",
              "             'has': 136,\n",
              "             'plays': 137,\n",
              "             'car': 138,\n",
              "             'hand': 139,\n",
              "             'holds': 140,\n",
              "             'it': 141,\n",
              "             'road': 142,\n",
              "             'him': 143,\n",
              "             'bench': 144,\n",
              "             'old': 145,\n",
              "             'glasses': 146,\n",
              "             'pants': 147,\n",
              "             'shorts': 148,\n",
              "             'stage': 149,\n",
              "             'sit': 150,\n",
              "             'carrying': 151,\n",
              "             'walk': 152,\n",
              "             'baby': 153,\n",
              "             'couple': 154,\n",
              "             'them': 155,\n",
              "             'side': 156,\n",
              "             'bicycle': 157,\n",
              "             'face': 158,\n",
              "             'tree': 159,\n",
              "             '\"': 160,\n",
              "             'male': 161,\n",
              "             'pool': 162,\n",
              "             'long': 163,\n",
              "             'race': 164,\n",
              "             'taking': 165,\n",
              "             'rock': 166,\n",
              "             'each': 167,\n",
              "             'middle': 168,\n",
              "             'doing': 169,\n",
              "             'dirt': 170,\n",
              "             'across': 171,\n",
              "             'head': 172,\n",
              "             'watching': 173,\n",
              "             'guy': 174,\n",
              "             'jeans': 175,\n",
              "             'there': 176,\n",
              "             'area': 177,\n",
              "             'dark': 178,\n",
              "             'jumps': 179,\n",
              "             'boat': 180,\n",
              "             'hands': 181,\n",
              "             'back': 182,\n",
              "             'female': 183,\n",
              "             'day': 184,\n",
              "             'ground': 185,\n",
              "             'performing': 186,\n",
              "             'room': 187,\n",
              "             'baseball': 188,\n",
              "             'who': 189,\n",
              "             'eating': 190,\n",
              "             'being': 191,\n",
              "             'football': 192,\n",
              "             'coat': 193,\n",
              "             'striped': 194,\n",
              "             'using': 195,\n",
              "             'kids': 196,\n",
              "             'suit': 197,\n",
              "             'horse': 198,\n",
              "             'under': 199,\n",
              "             'band': 200,\n",
              "             'watch': 201,\n",
              "             'many': 202,\n",
              "             'mouth': 203,\n",
              "             'purple': 204,\n",
              "             'he': 205,\n",
              "             'sign': 206,\n",
              "             'store': 207,\n",
              "             't': 208,\n",
              "             'this': 209,\n",
              "             'haired': 210,\n",
              "             'sand': 211,\n",
              "             'runs': 212,\n",
              "             'tennis': 213,\n",
              "             'look': 214,\n",
              "             'players': 215,\n",
              "             'construction': 216,\n",
              "             'sunglasses': 217,\n",
              "             'reading': 218,\n",
              "             'clothing': 219,\n",
              "             'microphone': 220,\n",
              "             'mountain': 221,\n",
              "             'covered': 222,\n",
              "             'toy': 223,\n",
              "             'basketball': 224,\n",
              "             'ocean': 225,\n",
              "             'during': 226,\n",
              "             'its': 227,\n",
              "             'workers': 228,\n",
              "             'watches': 229,\n",
              "             'climbing': 230,\n",
              "             'uniform': 231,\n",
              "             'past': 232,\n",
              "             'elderly': 233,\n",
              "             'helmet': 234,\n",
              "             'restaurant': 235,\n",
              "             'against': 236,\n",
              "             'team': 237,\n",
              "             'train': 238,\n",
              "             'dancing': 239,\n",
              "             'window': 240,\n",
              "             'rides': 241,\n",
              "             'shirts': 242,\n",
              "             'chair': 243,\n",
              "             'they': 244,\n",
              "             'work': 245,\n",
              "             'about': 246,\n",
              "             'be': 247,\n",
              "             'wooden': 248,\n",
              "             'posing': 249,\n",
              "             'trees': 250,\n",
              "             'five': 251,\n",
              "             'having': 252,\n",
              "             'outdoor': 253,\n",
              "             'waiting': 254,\n",
              "             'all': 255,\n",
              "             'swimming': 256,\n",
              "             'getting': 257,\n",
              "             'or': 258,\n",
              "             'floor': 259,\n",
              "             'trying': 260,\n",
              "             'ice': 261,\n",
              "             'very': 262,\n",
              "             'colorful': 263,\n",
              "             'skateboard': 264,\n",
              "             'bag': 265,\n",
              "             'high': 266,\n",
              "             'busy': 267,\n",
              "             'fence': 268,\n",
              "             'singing': 269,\n",
              "             'jump': 270,\n",
              "             'cart': 271,\n",
              "             'line': 272,\n",
              "             'laying': 273,\n",
              "             'hill': 274,\n",
              "             'market': 275,\n",
              "             'truck': 276,\n",
              "             'book': 277,\n",
              "             'bright': 278,\n",
              "             'hats': 279,\n",
              "             'inside': 280,\n",
              "             'ride': 281,\n",
              "             'tan': 282,\n",
              "             'cap': 283,\n",
              "             'kitchen': 284,\n",
              "             'others': 285,\n",
              "             'cellphone': 286,\n",
              "             'grassy': 287,\n",
              "             'path': 288,\n",
              "             'big': 289,\n",
              "             'someone': 290,\n",
              "             'brick': 291,\n",
              "             'making': 292,\n",
              "             'bus': 293,\n",
              "             'clothes': 294,\n",
              "             'motorcycle': 295,\n",
              "             'takes': 296,\n",
              "             'umbrella': 297,\n",
              "             'full': 298,\n",
              "             'light': 299,\n",
              "             'outfit': 300,\n",
              "             'towards': 301,\n",
              "             'track': 302,\n",
              "             'body': 303,\n",
              "             'enjoying': 304,\n",
              "             'night': 305,\n",
              "             'colored': 306,\n",
              "             'metal': 307,\n",
              "             'swing': 308,\n",
              "             'river': 309,\n",
              "             'open': 310,\n",
              "             'paper': 311,\n",
              "             'ready': 312,\n",
              "             'she': 313,\n",
              "             'tank': 314,\n",
              "             'piece': 315,\n",
              "             'shop': 316,\n",
              "             'sweater': 317,\n",
              "             'lake': 318,\n",
              "             'trick': 319,\n",
              "             'above': 320,\n",
              "             'painting': 321,\n",
              "             'run': 322,\n",
              "             'worker': 323,\n",
              "             'african': 324,\n",
              "             'hard': 325,\n",
              "             'adults': 326,\n",
              "             'american': 327,\n",
              "             'going': 328,\n",
              "             'music': 329,\n",
              "             'dance': 330,\n",
              "             'snowy': 331,\n",
              "             'shopping': 332,\n",
              "             'stone': 333,\n",
              "             'surrounded': 334,\n",
              "             'wave': 335,\n",
              "             'onto': 336,\n",
              "             'stick': 337,\n",
              "             'uniforms': 338,\n",
              "             'vest': 339,\n",
              "             'like': 340,\n",
              "             'outdoors': 341,\n",
              "             'photo': 342,\n",
              "             'backpack': 343,\n",
              "             'beside': 344,\n",
              "             'crowded': 345,\n",
              "             'smiles': 346,\n",
              "             'board': 347,\n",
              "             'kid': 348,\n",
              "             'phone': 349,\n",
              "             'pole': 350,\n",
              "             'drinking': 351,\n",
              "             'gear': 352,\n",
              "             'hockey': 353,\n",
              "             'subway': 354,\n",
              "             'family': 355,\n",
              "             'house': 356,\n",
              "             'toddler': 357,\n",
              "             'event': 358,\n",
              "             'gathered': 359,\n",
              "             'guys': 360,\n",
              "             'hanging': 361,\n",
              "             'police': 362,\n",
              "             'set': 363,\n",
              "             'arms': 364,\n",
              "             'bridge': 365,\n",
              "             'catch': 366,\n",
              "             'flowers': 367,\n",
              "             'away': 368,\n",
              "             'beautiful': 369,\n",
              "             'preparing': 370,\n",
              "             'fire': 371,\n",
              "             'costume': 372,\n",
              "             'leaning': 373,\n",
              "             'object': 374,\n",
              "             'sleeping': 375,\n",
              "             'after': 376,\n",
              "             'fishing': 377,\n",
              "             'steps': 378,\n",
              "             'bar': 379,\n",
              "             'does': 380,\n",
              "             'lot': 381,\n",
              "             'machine': 382,\n",
              "             'fountain': 383,\n",
              "             'plaid': 384,\n",
              "             'rope': 385,\n",
              "             'short': 386,\n",
              "             'adult': 387,\n",
              "             'shirtless': 388,\n",
              "             'take': 389,\n",
              "             'graffiti': 390,\n",
              "             'stairs': 391,\n",
              "             'rocks': 392,\n",
              "             'shoes': 393,\n",
              "             'arm': 394,\n",
              "             'selling': 395,\n",
              "             'sunny': 396,\n",
              "             'forest': 397,\n",
              "             'parade': 398,\n",
              "             'racing': 399,\n",
              "             'setting': 400,\n",
              "             'chairs': 401,\n",
              "             'glass': 402,\n",
              "             'pose': 403,\n",
              "             'tall': 404,\n",
              "             'both': 405,\n",
              "             'corner': 406,\n",
              "             'putting': 407,\n",
              "             'volleyball': 408,\n",
              "             'frisbee': 409,\n",
              "             'pushing': 410,\n",
              "             'throwing': 411,\n",
              "             'between': 412,\n",
              "             'drink': 413,\n",
              "             'have': 414,\n",
              "             'ladies': 415,\n",
              "             'slide': 416,\n",
              "             '2': 417,\n",
              "             'computer': 418,\n",
              "             'laughing': 419,\n",
              "             'public': 420,\n",
              "             'equipment': 421,\n",
              "             'flag': 422,\n",
              "             'instruments': 423,\n",
              "             'wood': 424,\n",
              "             'couch': 425,\n",
              "             'pictures': 426,\n",
              "             'sun': 427,\n",
              "             'view': 428,\n",
              "             'cowboy': 429,\n",
              "             'party': 430,\n",
              "             'plastic': 431,\n",
              "             'ramp': 432,\n",
              "             'aged': 433,\n",
              "             'concrete': 434,\n",
              "             'playground': 435,\n",
              "             'poses': 436,\n",
              "             'sweatshirt': 437,\n",
              "             'trail': 438,\n",
              "             'which': 439,\n",
              "             'woods': 440,\n",
              "             'beard': 441,\n",
              "             'fish': 442,\n",
              "             'statue': 443,\n",
              "             'dock': 444,\n",
              "             'midair': 445,\n",
              "             'winter': 446,\n",
              "             'yard': 447,\n",
              "             'number': 448,\n",
              "             'bikes': 449,\n",
              "             'seated': 450,\n",
              "             'skirt': 451,\n",
              "             'distance': 452,\n",
              "             'attire': 453,\n",
              "             'just': 454,\n",
              "             'reads': 455,\n",
              "             'school': 456,\n",
              "             'six': 457,\n",
              "             'toward': 458,\n",
              "             'what': 459,\n",
              "             'beer': 460,\n",
              "             'cooking': 461,\n",
              "             'get': 462,\n",
              "             'left': 463,\n",
              "             'sky': 464,\n",
              "             'works': 465,\n",
              "             'cutting': 466,\n",
              "             'rider': 467,\n",
              "             'vests': 468,\n",
              "             'bags': 469,\n",
              "             'buildings': 470,\n",
              "             'cream': 471,\n",
              "             'cross': 472,\n",
              "             'filled': 473,\n",
              "             'lined': 474,\n",
              "             'pulling': 475,\n",
              "             'where': 476,\n",
              "             'appears': 477,\n",
              "             'bed': 478,\n",
              "             'cliff': 479,\n",
              "             'skateboarder': 480,\n",
              "             'station': 481,\n",
              "             'tent': 482,\n",
              "             'crossing': 483,\n",
              "             'edge': 484,\n",
              "             'few': 485,\n",
              "             'friends': 486,\n",
              "             'instrument': 487,\n",
              "             'mountains': 488,\n",
              "             'showing': 489,\n",
              "             'spectators': 490,\n",
              "             'bearded': 491,\n",
              "             'cars': 492,\n",
              "             'court': 493,\n",
              "             'horses': 494,\n",
              "             'jersey': 495,\n",
              "             'mother': 496,\n",
              "             'make': 497,\n",
              "             'nearby': 498,\n",
              "             'performs': 499,\n",
              "             'right': 500,\n",
              "             'scarf': 501,\n",
              "             'apron': 502,\n",
              "             'bowling': 503,\n",
              "             'carries': 504,\n",
              "             'concert': 505,\n",
              "             'driving': 506,\n",
              "             'grill': 507,\n",
              "             'perform': 508,\n",
              "             'show': 509,\n",
              "             'snowboarder': 510,\n",
              "             'art': 511,\n",
              "             'fruit': 512,\n",
              "             'leaves': 513,\n",
              "             'shore': 514,\n",
              "             'boots': 515,\n",
              "             'cigarette': 516,\n",
              "             'coffee': 517,\n",
              "             'cup': 518,\n",
              "             'parked': 519,\n",
              "             'structure': 520,\n",
              "             'students': 521,\n",
              "             'various': 522,\n",
              "             'vendor': 523,\n",
              "             'gentleman': 524,\n",
              "             'goggles': 525,\n",
              "             'painted': 526,\n",
              "             'smile': 527,\n",
              "             'time': 528,\n",
              "             'vehicle': 529,\n",
              "             'younger': 530,\n",
              "             'bottle': 531,\n",
              "             'door': 532,\n",
              "             'dresses': 533,\n",
              "             'drums': 534,\n",
              "             'flower': 535,\n",
              "             'flying': 536,\n",
              "             'martial': 537,\n",
              "             'net': 538,\n",
              "             'smoking': 539,\n",
              "             'talks': 540,\n",
              "             'bathing': 541,\n",
              "             'eyes': 542,\n",
              "             'flags': 543,\n",
              "             'hit': 544,\n",
              "             'home': 545,\n",
              "             'kicking': 546,\n",
              "             'lying': 547,\n",
              "             'new': 548,\n",
              "             'no': 549,\n",
              "             'rocky': 550,\n",
              "             'shot': 551,\n",
              "             'surfer': 552,\n",
              "             'arts': 553,\n",
              "             'indian': 554,\n",
              "             'jackets': 555,\n",
              "             'newspaper': 556,\n",
              "             'paint': 557,\n",
              "             'prepares': 558,\n",
              "             'rain': 559,\n",
              "             'rodeo': 560,\n",
              "             'safety': 561,\n",
              "             'swinging': 562,\n",
              "             'waves': 563,\n",
              "             'box': 564,\n",
              "             'bucket': 565,\n",
              "             'conversation': 566,\n",
              "             'costumes': 567,\n",
              "             'different': 568,\n",
              "             'gather': 569,\n",
              "             'gloves': 570,\n",
              "             'parking': 571,\n",
              "             'practicing': 572,\n",
              "             'bunch': 573,\n",
              "             'cleaning': 574,\n",
              "             'competition': 575,\n",
              "             'ladder': 576,\n",
              "             'listening': 577,\n",
              "             'roof': 578,\n",
              "             'uses': 579,\n",
              "             'blanket': 580,\n",
              "             'items': 581,\n",
              "             'onlookers': 582,\n",
              "             'scene': 583,\n",
              "             'skateboarding': 584,\n",
              "             'staring': 585,\n",
              "             'wet': 586,\n",
              "             'audience': 587,\n",
              "             'balloon': 588,\n",
              "             'bicycles': 589,\n",
              "             'bikini': 590,\n",
              "             'bull': 591,\n",
              "             'desk': 592,\n",
              "             'empty': 593,\n",
              "             'giving': 594,\n",
              "             'lawn': 595,\n",
              "             'meal': 596,\n",
              "             'pile': 597,\n",
              "             'railing': 598,\n",
              "             'drinks': 599,\n",
              "             'hot': 600,\n",
              "             'leaps': 601,\n",
              "             'military': 602,\n",
              "             'sports': 603,\n",
              "             'cake': 604,\n",
              "             'display': 605,\n",
              "             'gathering': 606,\n",
              "             'go': 607,\n",
              "             'hold': 608,\n",
              "             'pointing': 609,\n",
              "             'sliding': 610,\n",
              "             'vegetables': 611,\n",
              "             'basket': 612,\n",
              "             'before': 613,\n",
              "             'biker': 614,\n",
              "             'bowl': 615,\n",
              "             'class': 616,\n",
              "             'competing': 617,\n",
              "             'facing': 618,\n",
              "             'feet': 619,\n",
              "             'gold': 620,\n",
              "             'stop': 621,\n",
              "             'streets': 622,\n",
              "             'suits': 623,\n",
              "             'wedding': 624,\n",
              "             'bird': 625,\n",
              "             'cement': 626,\n",
              "             'flip': 627,\n",
              "             'helmets': 628,\n",
              "             'huge': 629,\n",
              "             'mask': 630,\n",
              "             'platform': 631,\n",
              "             'silver': 632,\n",
              "             'speaking': 633,\n",
              "             'classroom': 634,\n",
              "             'coming': 635,\n",
              "             'gets': 636,\n",
              "             'lit': 637,\n",
              "             'match': 638,\n",
              "             'teams': 639,\n",
              "             'tie': 640,\n",
              "             'alley': 641,\n",
              "             'bride': 642,\n",
              "             'climbs': 643,\n",
              "             'marathon': 644,\n",
              "             'purse': 645,\n",
              "             'sings': 646,\n",
              "             'ski': 647,\n",
              "             'skier': 648,\n",
              "             'surfboard': 649,\n",
              "             'surfing': 650,\n",
              "             'traditional': 651,\n",
              "             'tries': 652,\n",
              "             'wait': 653,\n",
              "             'animal': 654,\n",
              "             'can': 655,\n",
              "             'chasing': 656,\n",
              "             'counter': 657,\n",
              "             'fighting': 658,\n",
              "             'kissing': 659,\n",
              "             'musicians': 660,\n",
              "             'rail': 661,\n",
              "             'screen': 662,\n",
              "             'break': 663,\n",
              "             'country': 664,\n",
              "             'father': 665,\n",
              "             'females': 666,\n",
              "             'happy': 667,\n",
              "             'same': 668,\n",
              "             'skating': 669,\n",
              "             'stroller': 670,\n",
              "             'kneeling': 671,\n",
              "             'lap': 672,\n",
              "             'pass': 673,\n",
              "             'runner': 674,\n",
              "             'shoulder': 675,\n",
              "             'sunset': 676,\n",
              "             'throw': 677,\n",
              "             'waits': 678,\n",
              "             'walkway': 679,\n",
              "             'writing': 680,\n",
              "             '3': 681,\n",
              "             'attempting': 682,\n",
              "             'bald': 683,\n",
              "             'business': 684,\n",
              "             'christmas': 685,\n",
              "             'scooter': 686,\n",
              "             'seen': 687,\n",
              "             'sort': 688,\n",
              "             'talk': 689,\n",
              "             'violin': 690,\n",
              "             'waving': 691,\n",
              "             'blowing': 692,\n",
              "             'outfits': 693,\n",
              "             'overlooking': 694,\n",
              "             'place': 695,\n",
              "             'signs': 696,\n",
              "             'artist': 697,\n",
              "             'bubbles': 698,\n",
              "             'chinese': 699,\n",
              "             'close': 700,\n",
              "             'course': 701,\n",
              "             'hole': 702,\n",
              "             'life': 703,\n",
              "             'mirror': 704,\n",
              "             'officer': 705,\n",
              "             'says': 706,\n",
              "             'son': 707,\n",
              "             'tables': 708,\n",
              "             'urban': 709,\n",
              "             'way': 710,\n",
              "             'balloons': 711,\n",
              "             'base': 712,\n",
              "             'brightly': 713,\n",
              "             'fixing': 714,\n",
              "             'giant': 715,\n",
              "             'leans': 716,\n",
              "             'lights': 717,\n",
              "             'alone': 718,\n",
              "             'brunette': 719,\n",
              "             'cafe': 720,\n",
              "             'collar': 721,\n",
              "             'do': 722,\n",
              "             'end': 723,\n",
              "             'faces': 724,\n",
              "             'foreground': 725,\n",
              "             'gym': 726,\n",
              "             'helping': 727,\n",
              "             'leather': 728,\n",
              "             'leg': 729,\n",
              "             'made': 730,\n",
              "             'swim': 731,\n",
              "             'teenage': 732,\n",
              "             'umbrellas': 733,\n",
              "             'asleep': 734,\n",
              "             'clown': 735,\n",
              "             'electric': 736,\n",
              "             'enjoy': 737,\n",
              "             'headphones': 738,\n",
              "             'legs': 739,\n",
              "             'meat': 740,\n",
              "             'mud': 741,\n",
              "             'plate': 742,\n",
              "             'site': 743,\n",
              "             'skate': 744,\n",
              "             'well': 745,\n",
              "             'among': 746,\n",
              "             'dancers': 747,\n",
              "             'diving': 748,\n",
              "             'falling': 749,\n",
              "             'golf': 750,\n",
              "             'makes': 751,\n",
              "             'office': 752,\n",
              "             'officers': 753,\n",
              "             'passing': 754,\n",
              "             'roller': 755,\n",
              "             'sandals': 756,\n",
              "             'stadium': 757,\n",
              "             'sticks': 758,\n",
              "             'swings': 759,\n",
              "             'washing': 760,\n",
              "             'wears': 761,\n",
              "             'barefoot': 762,\n",
              "             'canoe': 763,\n",
              "             'church': 764,\n",
              "             'dirty': 765,\n",
              "             'doorway': 766,\n",
              "             'goal': 767,\n",
              "             'heads': 768,\n",
              "             'multicolored': 769,\n",
              "             'musical': 770,\n",
              "             'photographer': 771,\n",
              "             'skiing': 772,\n",
              "             'toys': 773,\n",
              "             'accordion': 774,\n",
              "             'drawing': 775,\n",
              "             'laptop': 776,\n",
              "             'leash': 777,\n",
              "             'males': 778,\n",
              "             'picking': 779,\n",
              "             'reaching': 780,\n",
              "             'singer': 781,\n",
              "             'throws': 782,\n",
              "             'traffic': 783,\n",
              "             'video': 784,\n",
              "             'below': 785,\n",
              "             'digging': 786,\n",
              "             'hiking': 787,\n",
              "             'members': 788,\n",
              "             'performance': 789,\n",
              "             'relaxing': 790,\n",
              "             'row': 791,\n",
              "             'shallow': 792,\n",
              "             'wheel': 793,\n",
              "             'atop': 794,\n",
              "             'bicyclist': 795,\n",
              "             'cat': 796,\n",
              "             'catches': 797,\n",
              "             'catching': 798,\n",
              "             'deep': 799,\n",
              "             'foot': 800,\n",
              "             'gives': 801,\n",
              "             'hugging': 802,\n",
              "             'microscope': 803,\n",
              "             'passes': 804,\n",
              "             'shovel': 805,\n",
              "             'square': 806,\n",
              "             'tunnel': 807,\n",
              "             'upside': 808,\n",
              "             'van': 809,\n",
              "             'balls': 810,\n",
              "             'beige': 811,\n",
              "             'chef': 812,\n",
              "             'climb': 813,\n",
              "             'cut': 814,\n",
              "             'drum': 815,\n",
              "             'fun': 816,\n",
              "             'garden': 817,\n",
              "             'kick': 818,\n",
              "             'leaping': 819,\n",
              "             'prepare': 820,\n",
              "             'shows': 821,\n",
              "             'sleeps': 822,\n",
              "             'stunt': 823,\n",
              "             'sweeping': 824,\n",
              "             'tattoo': 825,\n",
              "             'coats': 826,\n",
              "             'cold': 827,\n",
              "             'conversing': 828,\n",
              "             'daughter': 829,\n",
              "             'desert': 830,\n",
              "             'flies': 831,\n",
              "             'here': 832,\n",
              "             'hoodie': 833,\n",
              "             'hose': 834,\n",
              "             'individuals': 835,\n",
              "             'karate': 836,\n",
              "             'lots': 837,\n",
              "             'move': 838,\n",
              "             'photograph': 839,\n",
              "             'pond': 840,\n",
              "             'resting': 841,\n",
              "             'sculpture': 842,\n",
              "             'sled': 843,\n",
              "             'splashing': 844,\n",
              "             'teeth': 845,\n",
              "             'trunks': 846,\n",
              "             ';': 847,\n",
              "             'bat': 848,\n",
              "             'block': 849,\n",
              "             'customers': 850,\n",
              "             'friend': 851,\n",
              "             'held': 852,\n",
              "             'how': 853,\n",
              "             'jogging': 854,\n",
              "             'lone': 855,\n",
              "             'pier': 856,\n",
              "             'plants': 857,\n",
              "             'points': 858,\n",
              "             'telescope': 859,\n",
              "             'these': 860,\n",
              "             'tire': 861,\n",
              "             'town': 862,\n",
              "             'underneath': 863,\n",
              "             'wrestling': 864,\n",
              "             'cane': 865,\n",
              "             'carnival': 866,\n",
              "             'curly': 867,\n",
              "             'cyclist': 868,\n",
              "             'eat': 869,\n",
              "             'hiker': 870,\n",
              "             'including': 871,\n",
              "             'local': 872,\n",
              "             'moving': 873,\n",
              "             'opposing': 874,\n",
              "             'project': 875,\n",
              "             'shoulders': 876,\n",
              "             'themselves': 877,\n",
              "             'waters': 878,\n",
              "             'without': 879,\n",
              "             'circle': 880,\n",
              "             'cloth': 881,\n",
              "             'crosswalk': 882,\n",
              "             'crying': 883,\n",
              "             'dinner': 884,\n",
              "             'gun': 885,\n",
              "             'hula': 886,\n",
              "             'infant': 887,\n",
              "             'lab': 888,\n",
              "             'makeup': 889,\n",
              "             'matching': 890,\n",
              "             'mural': 891,\n",
              "             'paved': 892,\n",
              "             'produce': 893,\n",
              "             'pulled': 894,\n",
              "             'racket': 895,\n",
              "             'runners': 896,\n",
              "             'shoe': 897,\n",
              "             'straw': 898,\n",
              "             'taken': 899,\n",
              "             'trampoline': 900,\n",
              "             'tricks': 901,\n",
              "             'wooded': 902,\n",
              "             'athlete': 903,\n",
              "             'attempts': 904,\n",
              "             'bicyclists': 905,\n",
              "             'booth': 906,\n",
              "             'closed': 907,\n",
              "             'dances': 908,\n",
              "             'formal': 909,\n",
              "             'gymnast': 910,\n",
              "             'knee': 911,\n",
              "             'mat': 912,\n",
              "             'nose': 913,\n",
              "             'opening': 914,\n",
              "             'performer': 915,\n",
              "             'picnic': 916,\n",
              "             'rolling': 917,\n",
              "             'sewing': 918,\n",
              "             'stuffed': 919,\n",
              "             'surface': 920,\n",
              "             'trash': 921,\n",
              "             \"'\": 922,\n",
              "             'balcony': 923,\n",
              "             'blouse': 924,\n",
              "             'boxes': 925,\n",
              "             'center': 926,\n",
              "             'cheerleaders': 927,\n",
              "             'cow': 928,\n",
              "             'fight': 929,\n",
              "             'goes': 930,\n",
              "             'help': 931,\n",
              "             'hikers': 932,\n",
              "             'himself': 933,\n",
              "             'lays': 934,\n",
              "             'lunch': 935,\n",
              "             'neck': 936,\n",
              "             'oriental': 937,\n",
              "             'pedestrians': 938,\n",
              "             'pitcher': 939,\n",
              "             'pushes': 940,\n",
              "             'ring': 941,\n",
              "             'round': 942,\n",
              "             'sandy': 943,\n",
              "             'slope': 944,\n",
              "             'softball': 945,\n",
              "             'teenagers': 946,\n",
              "             'third': 947,\n",
              "             'wear': 948,\n",
              "             'bent': 949,\n",
              "             'button': 950,\n",
              "             'chases': 951,\n",
              "             'deck': 952,\n",
              "             'device': 953,\n",
              "             'festival': 954,\n",
              "             'hoop': 955,\n",
              "             'i': 956,\n",
              "             'indoor': 957,\n",
              "             'kind': 958,\n",
              "             'log': 959,\n",
              "             'not': 960,\n",
              "             'pulls': 961,\n",
              "             'puts': 962,\n",
              "             'seven': 963,\n",
              "             'skis': 964,\n",
              "             'speaks': 965,\n",
              "             'staircase': 966,\n",
              "             'turn': 967,\n",
              "             'books': 968,\n",
              "             'covering': 969,\n",
              "             'driver': 970,\n",
              "             'drives': 971,\n",
              "             'enjoys': 972,\n",
              "             'evening': 973,\n",
              "             'fallen': 974,\n",
              "             'gentlemen': 975,\n",
              "             'golden': 976,\n",
              "             'grocery': 977,\n",
              "             'heavy': 978,\n",
              "             'marching': 979,\n",
              "             'overalls': 980,\n",
              "             'robe': 981,\n",
              "             'shaking': 982,\n",
              "             'swims': 983,\n",
              "             'wetsuit': 984,\n",
              "             'birds': 985,\n",
              "             'cloudy': 986,\n",
              "             'dancer': 987,\n",
              "             'fair': 988,\n",
              "             'fingers': 989,\n",
              "             'foreign': 990,\n",
              "             'garb': 991,\n",
              "             'hammer': 992,\n",
              "             'jean': 993,\n",
              "             'kayak': 994,\n",
              "             'khaki': 995,\n",
              "             'kicks': 996,\n",
              "             'laundry': 997,\n",
              "             'native': 998,\n",
              "             'nice': 999,\n",
              "             ...})"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(TRG.vocab.stoi[\"abcabc\"]) # 없는 단어: 0\n",
        "print(TRG.vocab.stoi[TRG.pad_token]) # 패딩(padding): 1\n",
        "print(TRG.vocab.stoi[\"<s>\"]) # <sos>: 2\n",
        "print(TRG.vocab.stoi[\"</s>\"]) # <eos>: 3\n",
        "print(TRG.vocab.stoi[\"water\"])\n",
        "print(TRG.vocab.stoi[\"world\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pwe7q0Wbf974",
        "outputId": "8d38450d-c991-4e0b-892d-5f8fac6262c1"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "47\n",
            "1752\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title **\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "DnsGJ6l2xdQH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# BucketIterator 생성(파이토치 데이터 로더 역할 수행) , 미니 배치 안의 문장들을 같은 크기로 맞춰주는 기능\n",
        "\n",
        "from torchtext.data import Field, BucketIterator\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "# 일반적인 데이터 로더(data loader)의 iterator와 유사하게 사용 가능\n",
        "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    device=device)\n",
        "\n",
        "print(next(iter(train_iterator)).src)\n",
        "print(next(iter(train_iterator)).src.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VI126UG5DYr1",
        "outputId": "0cc5f863-813b-48c4-d5ec-2da552835c26"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   8,   54,    5,  ...,    8,    5,    5],\n",
            "        [  16, 1551,  717,  ...,   36,   13,   13],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
            "torch.Size([33, 128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i, batch in enumerate(train_iterator):\n",
        "    src = batch.src\n",
        "    trg = batch.trg\n",
        "\n",
        "    print(f\"첫 번째 배치 크기: {src.shape}\")  # (batch_size, sequence_length)\n",
        "\n",
        "    # 현재 배치에 있는 하나의 문장에 포함된 정보 출력\n",
        "    for i in range(src.shape[1]):\n",
        "        print(f\"인덱스 {i}: {src[0][i].item()}\") # 여기에서는 [Seq_num, Seq_len]\n",
        "\n",
        "    # 첫 번째 배치만 확인\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s3ALALC70Gge",
        "outputId": "9c66b338-c527-4850-ca40-262bb2cd5b93"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "첫 번째 배치 크기: torch.Size([34, 128])\n",
            "인덱스 0: 2\n",
            "인덱스 1: 2\n",
            "인덱스 2: 2\n",
            "인덱스 3: 2\n",
            "인덱스 4: 2\n",
            "인덱스 5: 2\n",
            "인덱스 6: 2\n",
            "인덱스 7: 2\n",
            "인덱스 8: 2\n",
            "인덱스 9: 2\n",
            "인덱스 10: 2\n",
            "인덱스 11: 2\n",
            "인덱스 12: 2\n",
            "인덱스 13: 2\n",
            "인덱스 14: 2\n",
            "인덱스 15: 2\n",
            "인덱스 16: 2\n",
            "인덱스 17: 2\n",
            "인덱스 18: 2\n",
            "인덱스 19: 2\n",
            "인덱스 20: 2\n",
            "인덱스 21: 2\n",
            "인덱스 22: 2\n",
            "인덱스 23: 2\n",
            "인덱스 24: 2\n",
            "인덱스 25: 2\n",
            "인덱스 26: 2\n",
            "인덱스 27: 2\n",
            "인덱스 28: 2\n",
            "인덱스 29: 2\n",
            "인덱스 30: 2\n",
            "인덱스 31: 2\n",
            "인덱스 32: 2\n",
            "인덱스 33: 2\n",
            "인덱스 34: 2\n",
            "인덱스 35: 2\n",
            "인덱스 36: 2\n",
            "인덱스 37: 2\n",
            "인덱스 38: 2\n",
            "인덱스 39: 2\n",
            "인덱스 40: 2\n",
            "인덱스 41: 2\n",
            "인덱스 42: 2\n",
            "인덱스 43: 2\n",
            "인덱스 44: 2\n",
            "인덱스 45: 2\n",
            "인덱스 46: 2\n",
            "인덱스 47: 2\n",
            "인덱스 48: 2\n",
            "인덱스 49: 2\n",
            "인덱스 50: 2\n",
            "인덱스 51: 2\n",
            "인덱스 52: 2\n",
            "인덱스 53: 2\n",
            "인덱스 54: 2\n",
            "인덱스 55: 2\n",
            "인덱스 56: 2\n",
            "인덱스 57: 2\n",
            "인덱스 58: 2\n",
            "인덱스 59: 2\n",
            "인덱스 60: 2\n",
            "인덱스 61: 2\n",
            "인덱스 62: 2\n",
            "인덱스 63: 2\n",
            "인덱스 64: 2\n",
            "인덱스 65: 2\n",
            "인덱스 66: 2\n",
            "인덱스 67: 2\n",
            "인덱스 68: 2\n",
            "인덱스 69: 2\n",
            "인덱스 70: 2\n",
            "인덱스 71: 2\n",
            "인덱스 72: 2\n",
            "인덱스 73: 2\n",
            "인덱스 74: 2\n",
            "인덱스 75: 2\n",
            "인덱스 76: 2\n",
            "인덱스 77: 2\n",
            "인덱스 78: 2\n",
            "인덱스 79: 2\n",
            "인덱스 80: 2\n",
            "인덱스 81: 2\n",
            "인덱스 82: 2\n",
            "인덱스 83: 2\n",
            "인덱스 84: 2\n",
            "인덱스 85: 2\n",
            "인덱스 86: 2\n",
            "인덱스 87: 2\n",
            "인덱스 88: 2\n",
            "인덱스 89: 2\n",
            "인덱스 90: 2\n",
            "인덱스 91: 2\n",
            "인덱스 92: 2\n",
            "인덱스 93: 2\n",
            "인덱스 94: 2\n",
            "인덱스 95: 2\n",
            "인덱스 96: 2\n",
            "인덱스 97: 2\n",
            "인덱스 98: 2\n",
            "인덱스 99: 2\n",
            "인덱스 100: 2\n",
            "인덱스 101: 2\n",
            "인덱스 102: 2\n",
            "인덱스 103: 2\n",
            "인덱스 104: 2\n",
            "인덱스 105: 2\n",
            "인덱스 106: 2\n",
            "인덱스 107: 2\n",
            "인덱스 108: 2\n",
            "인덱스 109: 2\n",
            "인덱스 110: 2\n",
            "인덱스 111: 2\n",
            "인덱스 112: 2\n",
            "인덱스 113: 2\n",
            "인덱스 114: 2\n",
            "인덱스 115: 2\n",
            "인덱스 116: 2\n",
            "인덱스 117: 2\n",
            "인덱스 118: 2\n",
            "인덱스 119: 2\n",
            "인덱스 120: 2\n",
            "인덱스 121: 2\n",
            "인덱스 122: 2\n",
            "인덱스 123: 2\n",
            "인덱스 124: 2\n",
            "인덱스 125: 2\n",
            "인덱스 126: 2\n",
            "인덱스 127: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch.trg[:, 1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "An94uN6YClO-",
        "outputId": "2aa7cec1-6bdf-417e-e3c5-dba4c3d71b09"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([  2,   4,   9,   6,   4, 178,  81,  89,  71,  18,   4,   9,  73,   6,\n",
              "         61, 780,  40,  69,   4, 265,   5,   3,   1,   1,   1,   1,   1,   1,\n",
              "          1,   1,   1,   1,   1,   1,   1], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TRG.vocab.itos를 통해 토큰 인덱스를 해당 문자열 표현으로 반환 -> source 및 target sequences의 길이 및 크기를 출력\n",
        "# 최대 길이에 맞춰 padding이 이루어짐\n",
        "\n",
        "for i, batch in enumerate(train_iterator):\n",
        "    print(batch.trg.size())\n",
        "    items = [\" \".join([TRG.vocab.itos[item] for item in batch.trg[:, i]]) for i in range(128)]\n",
        "    for item in items:\n",
        "        print(item)\n",
        "\n",
        "    print(batch.src.size())\n",
        "    items = [\" \".join([SRC.vocab.itos[item] for item in batch.src[:, i]]) for i in range(128)]\n",
        "    for item in items:\n",
        "        print(item)\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rDVcCxsVBKzz",
        "outputId": "53c0ad97-f43b-410e-ad00-7c0516fedae2"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([34, 128])\n",
            "<s> man in <unk> <unk> logo shirt laying on a blue blanket , with arm around a toy - chewing infant . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> two young men perform martial arts in front of a basketball hoop . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> a man on a bridge holds a blue object over the rail . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> a worker <unk> the beams of a building being constructed . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> hundreds of people are running a marathon through a city . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> a woman carrying buckets in the mountains of the countryside . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> a little boy trying to brush a woman 's hair . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> three dogs are running side by side on the grass . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> a man in a green and white shirt and khakis skateboarding near sunset . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> two dogs shaking off water <unk> on a beach . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> a latino man leans on one of the coolers in his food stand . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> two white women playing tennis in front of a large crowd . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> a man wearing white shorts is riding a watercraft vehicle . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> a man wearing a light blue sweatshirt is sitting at a table in front of a budweiser bottle . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> a police officer is standing patrol at the corner near a red fire hydrant . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> a budweiser - sponsored race car <unk> quickly with smoke behind it . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> a boy jumping off a yellow spring board . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> a man doing a trick on a bike while in the air . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> two men are skiing and the one on the right is laughing </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> two opposing male players are chasing the ball in field hockey . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> two children are sliding down a water slide on an inflatable raft . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> a baby and a young child are sitting together in a highchair . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> a cheerleader dressed in an orange and white outfit is tossed in the air by four other cheerleaders on the ground . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> a child wearing a blue shirt and blue pants is standing in a park . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> a group of people are sitting underneath a tin roof . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> a small child , wearing a helmet , is riding a bmx bike on a dirt path . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> a bull is bucking off a rider who is wearing a pink shirt and <unk> . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> an individual is scrapping the bottom of their right food with a blade they have in their hand . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> an ambulance is near a pine tree . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> a group of amish people are standing outside of a church . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> a person swims in a body of water with a waterfall . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> a man in a workout suit is reading to a woman . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> a woman with brown curly hair , holding sunglasses , standing in a crowd . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> three children , wearing green , yellow , and blue uniforms , are sitting and standing near two women . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> a man is on a skateboard on a red ramp . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> two females , one wearing blue the other black , smiling and laughing </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> the black dog emerges from the water having collected an object in his teeth . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> an asian athlete in a bright jacket is <unk> by numerous reporters wearing rain jackets . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> an elderly person with a brick wall in the background . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> a policeman is roping off an area with police tape while onlookers watch . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> a little girl at a wedding holds a bouquet of orange flowers . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> a group of people run down a city street . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> the baby is wearing a bib and sitting in an adult ' </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> a baseball player sliding into home as the opposing team 's catcher awaits the baseball for the out . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> three young people planting flowers and covering the area with a tarp . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> a city street with a few passersby , featuring a cinder - block wall with graffiti on it . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> two men are getting dressed , and one of them is fixing his tie . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> a mother cradles her school - aged son in her arms . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> a heavy man wearing suspenders is sitting on a bench next to a huge balloon arrangement . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> five men in a laboratory are looking through microscopes . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> people outside in a field harvesting something . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> a guy name <unk> is setting something up behind a miniature railroad and other people in the back watching something on a drop down screen . </s> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> an african woman walks away from grass looking huts in a village carrying a back in her left hand . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> a group of people protesting by selling humans . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> a mom is very happy to be holding her new baby . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> a boy in a red hat and black shirt is skateboarding near a red and white striped curb . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> a young women sits in front of her computer and tries to study the fine print on a paper with the aid of a doctor 's spotlight attached to her head . </s>\n",
            "<s> children at maybe , at their school , or maybe , a field trip . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> a group of people drinking and talking </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> people getting tired while travelling . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> people are looking at pieces on display at a museum . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> a german shepherd is playing with a red ball . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> in this photo there are three teenagers playing soccer . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> a ribbon dancer is leaping through the air with her head back during a competition , green ribbon behind her . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> a child looking through a telescope on a playground . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> a man wearing a helmet rides a bright red motorcycle in traffic . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> a dog nips at the leg of a horse . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> several people are crossing the street at a crosswalk . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> a crowd gathers around a woman <unk> her head </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> a soccer player is chasing a ball off towards a sideline on the field . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> many people are standing and are watching something . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> a man is sitting at an outside bar near many soda and beer cans . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> two people rock climbing . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> people sitting in chairs with a row flags hanging over them . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> an athlete who 's glasses are falling off his face is lying down in a sandpit . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> two men from opposite teams playing basketball . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> a young man shows his excitement at an outdoor event at night . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> a small child in an <unk> shirt holds a cellphone to her ear . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> an older woman gets cash from her wallet at a another woman 's stand on the street . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> child playing in a pool with clean water . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> three people , all wearing dark clothing , stand talking at a street corner . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> a blond dog with floppy ears runs toward the camera . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> a man sits outside in the <unk> shade in a hammock reading something . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> a young man dunks a basketball . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> a group of people with their faces painted are standing outside . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> a baby in pink clothes staring at corn on the cob </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> a man is chopping up food on the ground . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> a black poodle with a rope toy in its mouth . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> three children jumping while an older man watches from a row of chairs nearby . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> a young boy in pajamas sleeps on a couch . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> a bowler throwing a ball down the lane trying to hit two pins . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> a skateboarder high in the air above an indoor ramp . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> a baby is getting his teeth <unk> . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> two brown dogs wearing muzzles race through a grassy field . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> four guys in wheelchairs on a basketball court two are trying to grab a basketball in midair . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> people <unk> gathered to honor a moment in time . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> young boy with red swim trunks playing in sand on the beach . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> a man in a tan jacket and blue jeans is sitting on a bench playing the guitar , with another man close - by . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> a man on machine talking to a guy dressed in a crazy outfit . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> a man driving a green miniature train . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> a woman in a brown dress is <unk> two men . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> an adult and a child are wearing ski equipment in the snow . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> a young girl in a pink shirt creates a painting on paper . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> adults stand around a classroom in africa . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> a girl wearing a halter top eats cake at a table . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> two workers face each other wearing green attire . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> three players participating in a team sport . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> three men , dressed in rain gear are standing on the dock of a boat preparing to clean fish . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> a blond woman is sitting under a turkey farm canopy . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> a woman is eating a sucker outside of a building . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> man sitting on a chair in the fields carving a statute supported by a tree trunk . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> a young man and woman are at a dinner table with food in front of them . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> an older women in several layers of clothes knits an item as , she sits near a set of stairs . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> a woman with a really dirty kitchen doing her dishes . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> a man crouches over his plants with various plants and dirt in the background . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> a man and a dog on rocks on a beach . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> many people are on the beach , near a building with flags flying . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> a food vendor selling food at a street market . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> numerous customers browsing for produce in a market . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> dog running in a field . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> a small child in a blue jacket is using his yellow pale to water a plant . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> hands with painted fingernails <unk> nail polish . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> blond woman driving a red bicycle carriage holds the tip of her hat and poses for the camera with a customer seated in the back . </s> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> a little boy is riding a yellow bicycle across a town square . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> four people are rowing in a canoe on a calm peaceful lake . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> a girl in a plaid dress is walking on a sidewalk next to a stone building . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> men walk down a street playing the drums . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> a girl in a flower dress is running on sand . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "torch.Size([33, 128])\n",
            "<s> ein mann mit einem t-shirt mit <unk> <unk> auf einer blauen decke , mit dem arm um einen <unk> säugling . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> zwei junge männer machen kampfsport vor einem basketballkorb . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> ein mann auf einer brücke hält einen blauen gegenstand über das geländer . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> ein arbeiter sitzt rittlings auf den balken eines im bau befindlichen gebäudes . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> hunderte von menschen laufen bei einem marathon durch eine stadt . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> eine frau trägt eimer in den bergen der ländlichen umgebung . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> ein kleiner junge versucht , die haare eine frau zu <unk> . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> drei hunde rennen nebeneinander auf dem gras . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> ein mann in einem grün-weißem oberteil und khakihose fährt kurz vor sonnenuntergang skateboard . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> zwei hunde schütteln am strand <unk> ab . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> ein <unk> mann lehnt sich an eine der kühlboxen an seinem essensstand . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> zwei hellhäutige frauen spielen vor einer großen menge tennis . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> ein mann in einer weißen kurzen hose fährt mit einem wasserfahrzeug . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> ein mann in einem hellblauen sweatshirt , sitzt an einem tisch vor einer <unk> flasche . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> ein polizist steht an der ecke neben einem roten hydranten <unk> . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> ein rennauto mit <unk> <unk> schnell und lässt rauch zurück . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> ein junge springt von einem gelben sprungbrett ab . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> ein mann führt in der luft einen trick auf seinem fahrrad vor . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> zwei männer fahren ski und der rechte davon lacht . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> zwei gegnerische männliche spieler jagen den ball beim feldhockey . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> zwei kinder rutschen eine wasserrutsche auf einem aufblasbaren floß hinunter . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> ein baby und ein kleinkind sitzen zusammen in einem hochstuhl . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> eine cheerleaderin in einem orangefarbenen und weißen outfit wird in die luft von vier anderen cheerleadern auf dem boden , geworfen . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> ein kind in blauem hemd und blauer hose steht in einem park . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> eine gruppe von personen sitzt unter einem <unk> . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> ein kleines kind mit helm fährt auf einem bmx-rad eine unbefestigte strecke entlang . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> ein bulle wirft einen reiter ab , der ein rosa oberteil und eine <unk> trägt . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> eine person kratzt die unterseite des rechten <unk> mit einem messer , das sie in der hand hält . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> ein krankenwagen in der nähe einer kiefer . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> eine gruppe von <unk> steht vor einer kirche . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> eine person schwimmt in einem gewässer mit einem wasserfall . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> ein mann in einem trainingsanzug liest einer frau vor . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> eine frau mit braunen locken hält eine sonnenbrille in der hand und steht in einer menschenmenge . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> drei kinder in grünen , gelben und blauen uniformen sitzen und stehen in der nähe von zwei frauen . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> ein mann ist auf einem skateboard auf einer roten rampe . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> zwei weibliche personen , die lächeln und lachen , eine blau gekleidet , die andere schwarz </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> der schwarze hund kommt aus dem wasser , nachdem er etwas mit seinen zähnen <unk> hat . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> ein asiatischer sportler in einer hellen jacke wird von vielen reportern in <unk> befragt . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> älterer mensch und ziegelmauer im hintergrund . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> ein polizist <unk> einen bereich ab während schaulustige dies beobachten . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> ein kleines mädchen auf einer hochzeit hält einen strauß orangefarbener blumen . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> eine gruppe von personen rennt auf einer städtischen straße . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> das baby trägt einen latz und sitzt einem erwachsenen auf dem <unk> . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> ein baseballspieler rutscht richtung home plate , während ein fänger des gegnerischen teams darauf wartet , dass der baseball ins aus geht . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> drei junge menschen pflanzen blumen und decken den bereich mit einer plane ab . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> in einer stadtstraße mit einigen passanten ist eine betonwand mit graffiti zu sehen . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> zwei männer werden <unk> , einer von ihnen befestigt seine krawatte . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> eine mutter hält ihren im schulalter befindlichen sohn im arm . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> ein schwerer mann mit sockenhaltern sitzt auf einer bank neben einer riesigen <unk> . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> fünf männer in einem labor schauen durch mikroskope . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> menschen im freien ernten etwas auf einem feld . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> ein mann namens <unk> baut etwas hinter einer modelleisenbahn auf , während andere personen im hintergrund sich etwas auf einer leinwand anschauen . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> eine afrikanische frau entfernt sich von den <unk> eines <unk> und hält eine tasche in ihrer linken hand . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> eine gruppe protestiert , indem sie menschen verkauft . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> eine mutter freut sich sehr , dass sie ihr neugeborenes baby hält . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> ein junge in roter mütze und schwarzem hemd fährt in der nähe einer <unk> bordsteinkante skateboard . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> eine junge frau sitzt vor einem computer und versucht mithilfe der an ihrem kopf <unk> <unk> des <unk> das <unk> auf einem blatt papier zu <unk> . </s> <blank> <blank> <blank> <blank>\n",
            "<s> kinder , die sich vielleicht in ihrer schule oder vielleicht auf einem <unk> befinden . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> eine gruppe <unk> und sich <unk> menschen . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> menschen auf der reise werden müde . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> personen schauen sich <unk> in einem museum an . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> ein deutscher schäferhund spielt mit einem roten ball . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> dieses foto zeigt drei jugendliche die fußball spielen . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> eine <unk> springt mit nach hinten geneigtem kopf durch die luft mit einem grünen band hinter ihr . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> ein kind schaut auf einem spielplatz durch ein teleskop . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> ein mann mit helm steuert ein hellrotes motorrad durch den <unk> . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> ein hund zwickt in das bein eines pferdes . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> mehrere personen überqueren die straße an einem fußgängerüberweg . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> eine menschenmenge hat sich um eine frau versammelt , die sich an den kopf greift . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> ein fußballspieler schießt einen ball richtung seitenlinie . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> viele menschen stehen herum und sehen etwas an . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> ein mann sitzt in einer bar im freien bei vielen <unk> und <unk> . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> zwei personen beim klettern . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> menschen sitzen auf stühlen , über ihnen hängt eine reihe von flaggen . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> ein sportler , dem die brille von der nase fällt , liegt in einer <unk> . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> zwei männer aus gegnerischen mannschaften spielen basketball . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> ein junger mann zeigt seine begeisterung nachts auf einer veranstaltung im freien . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> ein kleines kind in einem <unk> hält ein mobiltelefon ans ohr . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> eine ältere frau holt am straßenstand einer anderen frau geld aus ihrer geldbörse . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> ein kind spielt in einem schwimmbecken mit klarem wasser . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> drei personen , die alle dunkle kleidung tragen , unterhalten sich an einer straßenecke . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> ein heller hund mit <unk> rennt auf die kamera zu . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> ein mann sitzt im <unk> in einer hängematte und liest etwas . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> ein junger mann macht mit dem basketball einen dunking . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> eine gruppe leute mit geschminkten gesichtern steht im freien . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> ein baby in pinkfarbener kleidung schaut einen maiskolben an . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> ein mann zerkleinert essen auf dem boden . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> ein schwarzer pudel mit einem seilspielzeug in seiner schnauze . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> drei kinder , die springen , während ein älterer mann von einer <unk> in der nähe zusieht . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> ein junge im schlafanzug schläft auf einem sofa . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> ein bowlingspieler , der eine kugel wirft und versucht , zwei kegel zu treffen . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> ein skateboarder fliegt hoch in der luft über einer <unk> . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> einem baby werden die zähne <unk> . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> zwei braune hund mit maulkorb rennen auf einer wiese um die wette . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> vier männer in rollstühlen versuchen auf einem basketballplatz an einen in der luft fliegenden basketball zu gelangen . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> mehrere personen haben sich versammelt , um einem bestimmten <unk> zu <unk> . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> ein junge mit roter badehose spielt im sand am strand . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> ein mann in einer hellbraunen jacke und blauen jeans sitzt auf einer bank in der nähe eines anderen mannes und spielt gitarre . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> ein mann befindet sich an einer maschine und redet mit einem mann in verrückter kleidung . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> ein mann , der einen grünen <unk> fährt . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> eine frau in braunem kleid interviewt zwei männer . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> ein erwachsener und ein kind mit skiausrüstung im schnee . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> ein kleines mädchen in einem rosa oberteil malt auf papier . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> erwachsene stehen in einem klassenraum in afrika . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> ein mädchen mit einem bustier isst an einem tisch kuchen . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> zwei arbeiter in grüner kleidung schauen einander an . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> drei spieler nehmen an einer <unk> teil . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> drei männer in regenkleidung stehen an der anlegestelle eines bootes und bereiten sich auf das <unk> der fische vor . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> eine blonde frau sitzt unter dem vordach eines <unk> . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> eine frau isst außen vor einem gebäude einen lutscher . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> ein mann sitzt auf einem stuhl und schnitzt an einer von einem baumstamm <unk> statue . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> ein junger mann und eine frau sitzen mit essen vor sich am esstisch . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> eine ältere frau in mehreren schichten kleidung sitzt bei einer treppe und strickt einen gegenstand . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> eine frau spült geschirr in einer sehr <unk> küche . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> ein mann bückt sich über seine pflanzen . im hintergrund sind verschiedene pflanzen und erde zu sehen . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> ein mann und ein hund auf felsen am strand . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> viele leute sind am strand in der nähe eines gebäudes mit fahnen . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> ein essensverkäufer , der auf einem straßenmarkt essen verkauft . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> zahlreiche kunden stöbern in einem markt nach lebensmitteln . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> ein hund läuft auf einem feld . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> ein kleines kind in einer blauen jacke benutzt seine gelbe <unk> , um die pflanzen zu gießen . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> hände mit <unk> fingernägeln <unk> nagellack auf . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> eine blonde frau , die eine rote <unk> fährt , hält die spitze ihres <unk> und posiert für die kamera , während ein kunde im hinteren teil der kutsche sitzt . </s>\n",
            "<s> ein kleiner junge fährt auf einem gelben fahrrad über einen stadtplatz . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> vier personen rudern in einem kanu auf einem ruhigen , idyllischen see . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> ein mädchen in einem karierten kleid geht auf dem bürgersteig an einem steingebäude vorbei . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> männer gehen eine straße entlang und trommeln . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n",
            "<s> ein mädchen in einem blumenkleid rennt im sand . </s> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank> <blank>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install dill"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nKy_QCFh0qM6",
        "outputId": "713959ef-f1e1-4a01-b7f7-c31c48a146d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (0.3.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import dill as pickle\n",
        "import easydict\n",
        "\n",
        "opt = easydict.EasyDict({\n",
        "        \"lang_src\" : 'de_core_news_sm',# source 언어 / spacy 사용시\n",
        "        \"lang_trg\" : 'en_core_web_sm', # target 언어 / spacy 사용시\n",
        "        \"save_data\" : True,\n",
        "        \"data_src\" : None,\n",
        "        \"data_trg\" : None,\n",
        "        \"max_len\" :100, # 한 문장에 들어가는 최대 token 수 / 해당 갯수 이상이면 버림\n",
        "        \"min_word_count\" : 2, # vocab을 만들어 줄때 최소 갯수 : 해당 갯수 미만이면 <unk>로 vocab이 형성됨\n",
        "        \"keep_case\": True, # 대소문자 구분\n",
        "        \"share_vocab\" : \"store_true\",  # target vocab과 source vocab을 하나로 합치는지 여부\n",
        "    })\n"
      ],
      "metadata": {
        "id": "cxteX57t0iDb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for w, _ in SRC.vocab.stoi.items():\n",
        "    if w not in TRG.vocab.stoi:\n",
        "        TRG.vocab.stoi[w] = len(TRG.vocab.stoi)\n",
        "TRG.vocab.itos = [None] * len(TRG.vocab.stoi)\n",
        "for w, i in TRG.vocab.stoi.items():\n",
        "    TRG.vocab.itos[i] = w\n",
        "SRC.vocab.stoi = TRG.vocab.stoi\n",
        "SRC.vocab.itos = TRG.vocab.itos\n",
        "print('[Info] Get merged vocabulary size:', len(TRG.vocab))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UjHAQp0e0Iy8",
        "outputId": "08dcbe65-97d6-47f5-e265-c67d02647ab6"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Info] Get merged vocabulary size: 13269\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = {\n",
        "    'vocab': {'src': SRC, 'trg': TRG},\n",
        "    'train': train_data.examples,\n",
        "    'valid': valid_data.examples,\n",
        "    'test': test_data.examples}\n"
      ],
      "metadata": {
        "id": "6hXETiC30I56"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 1. Positional Encoding"
      ],
      "metadata": {
        "id": "-M5Pkv-iCkP-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "vacab_len = 13269\n",
        "\n",
        "embedding_layer = nn.Embedding(num_embeddings=vacab_len,\n",
        "                               embedding_dim=512,\n",
        "                               padding_idx=1)\n",
        "\n",
        "print(f'LOOK UP TABLE SIZE:  {embedding_layer.weight.shape}')\n",
        "print(embedding_layer.weight)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SPxirVas1YwW",
        "outputId": "ce1378b3-7a69-4fc1-eeca-efaf1c5d5e87"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LOOK UP TABLE SIZE:  torch.Size([13269, 512])\n",
            "Parameter containing:\n",
            "tensor([[-0.1117, -0.4966,  0.1631,  ...,  0.9230, -0.6661, -0.6180],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.5411,  0.8900, -0.2705,  ..., -1.0925, -0.7953,  2.1657],\n",
            "        ...,\n",
            "        [ 0.2053, -0.2856,  1.3139,  ...,  2.4629, -1.6645, -1.5972],\n",
            "        [ 2.0385,  0.7906, -2.6038,  ..., -0.9524, -0.8998,  1.2526],\n",
            "        [-0.9399, -0.3463, -1.2625,  ..., -1.9454,  1.2405, -0.9553]],\n",
            "       requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "\n",
        "class Positional_Encoding(nn.Module):\n",
        "    def __init__(self, d_hid, max_length=200):\n",
        "        super(Positional_Encoding, self).__init__()\n",
        "\n",
        "        self.register_buffer('pos_table', self._get_sinusoid_encoding_table(max_length, d_hid))\n",
        "\n",
        "    def _get_sinusoid_encoding_table(self, max_length, d_hid):\n",
        "        '''Sinusoid position encoding table'''\n",
        "\n",
        "        def get_position_angle_vec(position):\n",
        "            return [position / np.power(10000, 2 * (hid_j // 2) / d_hid) for hid_j in range(d_hid)]\n",
        "\n",
        "        sinusoid_table = np.array([get_position_angle_vec(pos_i) for pos_i in range(max_length)])\n",
        "        sinusoid_table[:, 0::2] = np.sin(sinusoid_table[:, 0::2])     # 짝수 번째 인덱스는 sin 함수 적용\n",
        "        sinusoid_table[:, 1::2] = np.cos(sinusoid_table[:, 1::2])     # 홀수 번째 인덱스는 cos 함수 적\n",
        "\n",
        "        return torch.FloatTensor(sinusoid_table).unsqueeze(0)   # numpy 배열을 PyTorch FloatTensor로 변환한 다음 unsqueze(0)를 사용하여 텐서에 추가 차원을 추가\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.pos_table[:, :x.size(1)].clone().detach()\n",
        "\n",
        "\n",
        "# 위치 인코딩을 입력 텐서 x에 추가"
      ],
      "metadata": {
        "id": "CFLElxBQy1Hl"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 2. Scaled dot-product\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "tV0Y7x0uO8RI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "class ScaledDotProduct_Attention(nn.Module):\n",
        "    ''' Scaled Dot-Product Attention '''\n",
        "\n",
        "    def __init__(self, temperature, attn_dropout=0.1):    # (스케일링 계수 temp, dropout 비율 attn_dropout)\n",
        "        super().__init__()\n",
        "        self.temperature = temperature\n",
        "        self.dropout = nn.Dropout(attn_dropout)\n",
        "\n",
        "    def forward(self, q, k, v, mask=None):\n",
        "\n",
        "        # ① attention score 계산\n",
        "        attn = torch.matmul(q / self.temperature, k.transpose(2, 3))         # (batch_size, num_heads, query_length, key_length)가\n",
        "\n",
        "        # ② attention을 계산하지 않는 위치를 매우 작은 값으로 치환\n",
        "        # - 매우작은 값은 softmax를 거칠때 0과 가까운 값이 되므로 무시한다.\n",
        "        if mask is not None:\n",
        "            attn = attn.masked_fill(mask == 0, -1e9)\n",
        "\n",
        "        # ③ soft max를 이용하여 attention weight 계산\n",
        "        attn = self.dropout(F.softmax(attn, dim=-1))\n",
        "\n",
        "        # ④ 해당 분포값에 v를 곱하여 attention value를 구한다            # (batch_size, num_heads, query_length, value_dimension)을 생\n",
        "        output = torch.matmul(attn, v)\n",
        "\n",
        "        return output, attn\n",
        "        # attention values, attention weight"
      ],
      "metadata": {
        "id": "cOzMtoNay1Mq"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def scaled_dot_product_attention(q, k, v, mask=None):\n",
        "\n",
        "    matmul_qk = torch.matmul(q, k.transpose(-2, -1))\n",
        "\n",
        "    dk = torch.tensor(k.shape[-1], dtype=torch.float32)\n",
        "\n",
        "    scaled_attention_logits = matmul_qk / torch.sqrt(dk)\n",
        "\n",
        "    if mask is not None:\n",
        "        scaled_attention_logits = scaled_attention_logits + (mask * -1e9)\n",
        "\n",
        "    softmax = torch.softmax(scaled_attention_logits, dim=-1)\n",
        "\n",
        "    output = torch.matmul(softmax, v)\n",
        "\n",
        "    return output, softmax"
      ],
      "metadata": {
        "id": "hzaodljXxjLQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 3. Multihead attention"
      ],
      "metadata": {
        "cellView": "form",
        "id": "jdtiIWrJXsUf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    ''' Multi-Head Attention module '''\n",
        "\n",
        "    def __init__(self, n_heads, d_model, d_k, d_v, device, dropout=0.1):\n",
        "        super().__init__()\n",
        "\n",
        "        assert d_model % n_heads == 0\n",
        "\n",
        "        self.n_heads = n_heads        # 헤드(head)의 개수: 서로 다른 어텐션(attention) 컨셉의 수\n",
        "        self.d_model = d_model\n",
        "        self.d_k = d_k\n",
        "        self.d_v = d_v\n",
        "\n",
        "        self.w_q = nn.Linear(d_model, n_heads * d_k, bias=False)\n",
        "        self.w_k = nn.Linear(d_model, n_heads * d_k, bias=False)\n",
        "        self.w_v = nn.Linear(d_model, n_heads * d_v, bias=False)\n",
        "\n",
        "        self.fc = nn.Linear(n_heads* d_v, d_model, bias=False)\n",
        "\n",
        "        self.attention = ScaledDotProduct_Attention(temperature=d_k ** 0.5).to(device)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.layer_norm = nn.LayerNorm(d_model, eps=1e-6)\n",
        "\n",
        "\n",
        "    def forward(self, q, k, v, mask=None):\n",
        "\n",
        "        d_k, d_v, n_heads = self.d_k, self.d_v, self.n_heads\n",
        "        sz_b, len_q, len_k, len_v = q.size(0), q.size(1), k.size(1), v.size(1)\n",
        "\n",
        "        print(\"Shape of q:\", q.shape)\n",
        "        print(\"Shape of k:\", k.shape)\n",
        "        print(\"Shape of v:\", v.shape)\n",
        "\n",
        "        residual = q\n",
        "\n",
        "        # Pass through the pre-attention projection: b x lq x (n*dv)\n",
        "        # Separate different heads: b x lq x n x dv\n",
        "        q = self.w_q(q).view(sz_b, len_q, n_heads, d_k) # [256, len, 8, 64]\n",
        "        k = self.w_k(k).view(sz_b, len_k, n_heads, d_k) # [256, len, 8, 64]\n",
        "        v = self.w_v(v).view(sz_b, len_v, n_heads, d_v) # [256, len, 8, 64]\n",
        "\n",
        "\n",
        "        # Transpose for attention dot product: b x n x lq x dv\n",
        "        q, k, v = q.transpose(1, 2), k.transpose(1, 2), v.transpose(1, 2) # [256, 8, len, 64]\n",
        "\n",
        "        if mask is not None:\n",
        "            mask = mask.unsqueeze(1)   # For head axis broadcasting.\n",
        "\n",
        "        q, attn = self.attention(q, k, v, mask=mask)    # 하나의 차원의 attention 값으로 출력되는 것\n",
        "\n",
        "        # Transpose to move the head dimension back: b x lq x n x dv\n",
        "        # Combine the last two dimensions to concatenate all the heads together: b x lq x (n*dv)\n",
        "        q = q.transpose(1, 2).contiguous().view(sz_b, len_q, -1) # [256, 36, 512]\n",
        "        q = self.dropout(self.fc(q))\n",
        "        q += residual\n",
        "\n",
        "        q = self.layer_norm(q)\n",
        "\n",
        "        return q, attn\n"
      ],
      "metadata": {
        "id": "VfuG6wHIDYva"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 4.  Position wise Feed Forward\n",
        "# -> specify한 부분을 처리하는 데 용이\n",
        "# d_hid: 하나의 단어에 대한 임베딩 차원\n",
        "# d_in: 입력 차원\n",
        "# dropout: 드롭아웃 비율\n"
      ],
      "metadata": {
        "id": "dghvRiGj3toj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Positionwise_FeedForward(nn.Module):\n",
        "    ''' A two-feed-forward-layer module '''\n",
        "\n",
        "    def __init__(self, d_in, d_hid, dropout=0.1):    # dropout 비율 바꿔가면서 해보기\n",
        "        super().__init__()\n",
        "        self.w_1 = nn.Linear(d_in, d_hid) # position-wise 512 -> 2048\n",
        "        self.w_2 = nn.Linear(d_hid, d_in) # position-wise 2048 -> 512\n",
        "        self.layer_norm = nn.LayerNorm(d_in, eps=1e-6)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        residual = x\n",
        "\n",
        "        x = self.dropout(F.relu(self.w_1(x)))\n",
        "        x = self.w_2(x)\n",
        "        x += residual\n",
        "\n",
        "        x = self.layer_norm(x)\n",
        "\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "mGGo-eR83wFf"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 5. Encoder Layer\n",
        "# 인코더의 셀프 어텐션: Query = Key = Value\n"
      ],
      "metadata": {
        "id": "lvMoTthS3wMb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 인코더 레이어는 입력과 출력 차원이 같음 -> 트랜스포머의 인코더는 인코더 레이어를 여러 번 중첩해서 사용 가능\n",
        "\n",
        "class EncoderLayer(nn.Module):\n",
        "    ''' Compose with two layers '''\n",
        "\n",
        "    def __init__(self, d_model, d_inner, n_heads, d_k, d_v, device, dropout=0.1):       # dropout 비율 바꿔가면서 해보기\n",
        "        super(EncoderLayer, self).__init__()\n",
        "\n",
        "        self.self_attn = MultiHeadAttention(n_heads, d_model, d_k, d_v, device, dropout=dropout)\n",
        "        self.pos_ffn = Positionwise_FeedForward(d_model, d_inner, dropout=dropout)\n",
        "        self.self_attn_layer_norm = nn.LayerNorm(d_model)\n",
        "        self.ff_layer_norm = nn.LayerNorm(d_model)\n",
        "        # self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, enc_input, src_mask=None):\n",
        "        enc_output, enc_slf_attn = self.self_attn(enc_input, enc_input, enc_input, mask=src_mask)\n",
        "        # enc_input을 각각 q, k ,v 값으로 self-attention 수행 후 출력 텐서와 attention 가중치 텐서를 반환\n",
        "        # enc_input = self.self_attn_layer_norm(enc_input + self.dropout(enc_input))         # dropout, residual connection and layer norm\n",
        "        enc_output = self.pos_ffn(enc_output)                                              # position-wise feedforward\n",
        "        # enc_input = self.ff_layer_norm(enc_input + self.dropout(enc_output))\n",
        "\n",
        "        return enc_output, enc_slf_attn\n"
      ],
      "metadata": {
        "id": "o9FffhGa3yqt"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# src_mask는 pad_idx에 대하여 mask값을 0으로 처리하는 함수로, 필요 없는 패딩 인덱스에 대해 attention 연산을 안 하겠다는 의미\n",
        "\n",
        "def get_pad_mask(seq, pad_idx):\n",
        "    return (seq != pad_idx).unsqueeze(-2)\n",
        ""
      ],
      "metadata": {
        "id": "uk26lILlhPGQ"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 6.  Encoder Architechture\n",
        "# Encoder의 구조 = token embedding + positional embedding -> a stack of N EncoderBlock -> layer norm"
      ],
      "metadata": {
        "id": "sbIH_7D93y9v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "    ''' A encoder model with self attention mechanism. '''\n",
        "\n",
        "    def __init__(\n",
        "            self, src_vocab, d_word_vec, n_layers, n_heads, d_k, d_v,\n",
        "            d_model, d_inner, pad_idx, device, dropout=0.1, max_length=200, scale_emb=False):\n",
        "\n",
        "\n",
        "        super().__init__()\n",
        "        self.device = device\n",
        "\n",
        "        # 모든 단어들을 embedding (고유 백터를 가진 차원으로 변경)\n",
        "        self.src_word_emb = nn.Embedding(src_vocab, d_word_vec, padding_idx=pad_idx)\n",
        "\n",
        "        # 문장의 최대 길이까지 positional encoding을 함\n",
        "        self.position_enc = Positional_Encoding(d_word_vec, max_length)\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        # multiple encoder\n",
        "        # encoder layer stack으로 encoder 층을 6개로 쌓는다.\n",
        "        # encoder layer : multihead attentions, feedforward로 구성\n",
        "        self.layer_stack = nn.ModuleList([\n",
        "            EncoderLayer(d_model, d_inner, n_heads, d_k, d_v, device, dropout=dropout)\n",
        "            for _ in range(n_layers)])\n",
        "\n",
        "        # layer_norm\n",
        "        self.layer_norm = nn.LayerNorm(d_model, eps=1e-6)\n",
        "        self.scale_emb = scale_emb\n",
        "        self.d_model = d_model\n",
        "\n",
        "    def forward(self, src_seq, src_mask, return_attns=True):\n",
        "\n",
        "        enc_slf_attn_list = []\n",
        "\n",
        "        # -- Forward\n",
        "        # ① word embedding\n",
        "        enc_output = self.src_word_emb(src_seq)\n",
        "        if self.scale_emb:\n",
        "            enc_output *= self.d_model ** 0.5\n",
        "\n",
        "        # ② positional encoding\n",
        "        enc_output = self.dropout(self.position_enc(enc_output))\n",
        "\n",
        "        # normalization\n",
        "        enc_output = self.layer_norm(enc_output).to(device)\n",
        "\n",
        "        # ③ stacked encoder layers\n",
        "        for enc_layer in self.layer_stack:\n",
        "            enc_output, enc_slf_attn = enc_layer(enc_output, src_mask)\n",
        "            enc_slf_attn_list += [enc_slf_attn] if return_attns else []\n",
        "\n",
        "        if return_attns:\n",
        "            return enc_output, enc_slf_attn_list\n",
        "        return enc_output\n"
      ],
      "metadata": {
        "id": "1FfTjl4e31pi"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://dongdong93.tistory.com/25\n",
        "# https://github.com/kimwoonggon/publicservant_AI/blob/master/%EC%8B%AC%ED%99%942_%ED%8A%B8%EB%9E%9C%EC%8A%A4%ED%8F%AC%EB%A8%B8_%EC%89%BD%EA%B2%8C%EA%B5%AC%ED%98%84%ED%95%B4%EB%B3%B4%EA%B8%B0.ipynb\n",
        "# https://github.com/jadore801120/attention-is-all-you-need-pytorch/blob/master/transformer/Models.py\n",
        "# https://github.com/hbchen-one/Transformer-Models-from-Scratch/blob/main/Transformer_Multi30k_German_to_English.ipynb\n",
        "# https://americanoisice.tistory.com/59\n",
        "# https://github.com/SethHWeidman/pytorch-seq2seq/blob/master/6%20-%20Attention%20is%20All%20You%20Need.ipynb"
      ],
      "metadata": {
        "id": "0MhJPV3BvgBK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Decoder Layer\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "E38xZLi231wB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 인코더 layer와 마찬가지로 입력과 출력의 차원이 같음 -> 트랜스포머의 디코더 또한 디코더 레이어를 여러 번 중첩해서 사용 가능\n",
        "# 두 개의 multihead attetion이 사용\n",
        "# masked multi-head attention을 하기 위한 mask 과정\n",
        "\n",
        "def get_subsequent_mask(seq):\n",
        "    ''' For masking out the subsequent info. '''\n",
        "    sz_b, len_s = seq.size()\n",
        "    subsequent_mask = (1 - torch.triu(\n",
        "        torch.ones((1, len_s, len_s), device=seq.device), diagonal=1)).bool()\n",
        "    return subsequent_mask\n",
        "\n",
        "# 대각행렬 윗부분을 False로 치환 -> 0으로 설정함으로써 미래 위치에 대한 예측이 이전에 생성된 위치만을 기반으로 함"
      ],
      "metadata": {
        "id": "Epd3wtJa34Eo"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderLayer(nn.Module):\n",
        "    ''' Compose with three layers '''\n",
        "\n",
        "    def __init__(self, d_model, d_inner, n_heads, d_k, d_v, device, dropout=0.1):\n",
        "        super(DecoderLayer, self).__init__()\n",
        "\n",
        "        self.self_attn = MultiHeadAttention(n_heads, d_model, d_k, d_v, device, dropout=dropout)  # decoder layer의 self-attention\n",
        "        self.enc_attn = MultiHeadAttention(n_heads, d_model, d_k, d_v, device, dropout=dropout)   # decoder-encoder layer의 self-attention\n",
        "        self.pos_ffn = Positionwise_FeedForward(d_model, d_inner, dropout=dropout)\n",
        "        self.self_attn_layer_norm = nn.LayerNorm(d_model)\n",
        "        self.ff_layer_norm = nn.LayerNorm(d_model)\n",
        "        # self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    # 인코더의 출력값을 attention하는 구조\n",
        "    def forward(\n",
        "            self, dec_input, enc_output,\n",
        "            src_mask=None, dec_mask=None):\n",
        "\n",
        "        # ① sublayer 1: decoder input 값, 자기 자신에 대한 self attention\n",
        "        dec_output, dec_slf_attn = self.self_attn(dec_input, dec_input, dec_input, mask=src_mask)\n",
        "        # dec_input = self.self_attn_layer_norm(dec_input + self.dropout(dec_output))\n",
        "\n",
        "        # ② sublayer 2 : ①의 결과값을 query로, key,value는 encoder의 output 값으로 attention - 디코더의 query를 이용해 인코더를 attention\n",
        "        dec_output, dec_enc_attn = self.enc_attn(dec_output, enc_output, enc_output, mask=dec_mask)\n",
        "        # dec_input = self.ff_layer_norm(dec_input + self.dropout(dec_output))\n",
        "\n",
        "        # ③ sublayer 3 : position wise feed forward를 통과\n",
        "        dec_output = self.pos_ffn(dec_output)\n",
        "\n",
        "\n",
        "        return dec_output, dec_slf_attn, dec_enc_attn\n"
      ],
      "metadata": {
        "id": "5JIwD666Faix"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "35qG7Gx63WuM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Decoder Architechture\n",
        "#"
      ],
      "metadata": {
        "id": "5jhFVPOJ34Ku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from thinc.layers.dropout import Dropout\n",
        "class Decoder(nn.Module):\n",
        "    ''' A decoder model with self attention mechanism. '''\n",
        "\n",
        "\n",
        "# trg_vocab: target 단어 수, d_word_vec: 단어 임베딩 차\n",
        "    def __init__(\n",
        "            self, trg_vocab, d_word_vec, n_layers, n_heads, d_k, d_v,\n",
        "            d_model, d_inner, pad_idx,device, dropout=0.1, max_length=200, scale_emb=False):\n",
        "\n",
        "        super().__init__()\n",
        "        self.device = device\n",
        "\n",
        "        # target word embedding\n",
        "        self.trg_word_emb = nn.Embedding(trg_vocab, d_word_vec, padding_idx=pad_idx)\n",
        "\n",
        "        # positional encoding\n",
        "        self.position_enc = Positional_Encoding(d_word_vec, max_length=max_length)\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "         # multiple decoder\n",
        "        self.layer_stack = nn.ModuleList([\n",
        "            DecoderLayer(d_model, d_inner, n_heads, d_k, d_v, device, dropout=dropout)\n",
        "            for _ in range(n_layers)])\n",
        "\n",
        "        # layer_normalization\n",
        "        self.layer_norm = nn.LayerNorm(d_model, eps=1e-6)\n",
        "        self.scale_emb = scale_emb\n",
        "        self.d_model = d_model\n",
        "\n",
        "    def forward(self, trg_seq, trg_mask, enc_output, src_mask, return_attns=True):\n",
        "\n",
        "        dec_slf_attn_list, dec_enc_attn_list = [], []\n",
        "\n",
        "        # -- Forward\n",
        "\n",
        "        # ① target words embedding\n",
        "        dec_output = self.trg_word_emb(trg_seq)\n",
        "        if self.scale_emb:\n",
        "            dec_output *= self.d_model ** 0.5\n",
        "\n",
        "        # ② positional encoding\n",
        "        dec_output = self.dropout(self.position_enc(dec_output))\n",
        "        dec_output = self.layer_norm(dec_output).to(device)\n",
        "\n",
        "        # ③ decoder_layer stacked\n",
        "        for dec_layer in self.layer_stack:\n",
        "            dec_output, dec_slf_attn, dec_enc_attn = dec_layer(\n",
        "                dec_output, enc_output, trg_mask, src_mask)\n",
        "\n",
        "            dec_slf_attn_list += [dec_slf_attn] if return_attns else []\n",
        "            dec_enc_attn_list += [dec_enc_attn] if return_attns else []\n",
        "\n",
        "        if return_attns:\n",
        "            return dec_output, dec_slf_attn_list, dec_enc_attn_list\n",
        "        return dec_output\n"
      ],
      "metadata": {
        "id": "cXtc6X_-3-1N"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YgPP_GH43XHn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Transformer Model"
      ],
      "metadata": {
        "id": "yvBWp6SI3-7B"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. source, target 데이터에 대한 mask 생성\n",
        "# 2. 인코더, 디코더 층 통과\n",
        "# 3. 최종 가중치 층을 통과해 출력 문장 생성\n",
        "\n",
        "''' Define the Transformer model '''\n",
        "\n",
        "# from transformer.Layers import EncoderLayer, DecoderLayer\n",
        "\n",
        "class Transformer(nn.Module):\n",
        "    ''' A sequence to sequence model with attention mechanism. '''\n",
        "\n",
        "    def __init__(\n",
        "            self, src_vocab, trg_vocab, src_pad_idx, trg_pad_idx, device,\n",
        "            d_word_vec=512, d_model=512, d_inner=2048,\n",
        "            n_layers=6, n_heads=8, d_k=64, d_v=64, max_length=200,\n",
        "            trg_emb_prj_weight_sharing=True, emb_src_trg_weight_sharing=True,\n",
        "            scale_emb_or_prj='prj'):\n",
        "\n",
        "        super().__init__()\n",
        "        self.device = device\n",
        "        self.dropout = 0.1\n",
        "\n",
        "        # padding index 저장\n",
        "        self.src_pad_idx = src_pad_idx\n",
        "        self.trg_pad_idx = trg_pad_idx\n",
        "\n",
        "        assert scale_emb_or_prj in ['emb', 'prj', 'none']\n",
        "        scale_emb = (scale_emb_or_prj == 'emb') if trg_emb_prj_weight_sharing else False\n",
        "        self.scale_prj = (scale_emb_or_prj == 'prj') if trg_emb_prj_weight_sharing else False\n",
        "        self.d_model = d_model\n",
        "\n",
        "        # encoder 정의\n",
        "        self.encoder = Encoder(\n",
        "            src_vocab=src_vocab, max_length=max_length,\n",
        "            d_word_vec=d_word_vec, d_model=d_model, d_inner=d_inner,\n",
        "            n_layers=n_layers, n_heads=n_heads, d_k=d_k, d_v=d_v,\n",
        "            pad_idx=src_pad_idx, dropout=dropout, scale_emb=scale_emb, device=device)\n",
        "\n",
        "        # decoder 정의\n",
        "        self.decoder = Decoder(\n",
        "            trg_vocab=trg_vocab, max_length=max_length,\n",
        "            d_word_vec=d_word_vec, d_model=d_model, d_inner=d_inner,\n",
        "            n_layers=n_layers, n_heads=n_heads, d_k=d_k, d_v=d_v,\n",
        "            pad_idx=trg_pad_idx, dropout= dropout, scale_emb=scale_emb, device=device)\n",
        "\n",
        "        # 최종 output layers 정의\n",
        "        self.trg_word_prj = nn.Linear(d_model, trg_vocab, bias=False)\n",
        "\n",
        "        for p in self.parameters():\n",
        "            if p.dim() > 1:\n",
        "                nn.init.xavier_uniform_(p)\n",
        "\n",
        "        assert d_model == d_word_vec, \\\n",
        "            'To facilitate the residual connections, ' \\\n",
        "            'the dimensions of all module outputs shall be the same.'\n",
        "\n",
        "        if trg_emb_prj_weight_sharing:\n",
        "            # Share the weight between target word embedding & last dense layer\n",
        "            self.trg_word_prj.weight = self.decoder.trg_word_emb.weight\n",
        "\n",
        "        if emb_src_trg_weight_sharing:\n",
        "            self.encoder.src_word_emb.weight = self.decoder.trg_word_emb.weight\n",
        "\n",
        "\n",
        "    def forward(self, src_seq, trg_seq):\n",
        "\n",
        "        # ① source, target 데이터에 대한 mask 생성\n",
        "        src_mask = get_pad_mask(src_seq, self.src_pad_idx)\n",
        "        trg_mask = get_pad_mask(trg_seq, self.trg_pad_idx) & get_subsequent_mask(trg_seq)\n",
        "\n",
        "        # ② encoder 층을 통과\n",
        "        enc_output, *_ = self.encoder(src_seq, src_mask)\n",
        "\n",
        "        # ③ decoder 층을 통과\n",
        "        dec_output, attention1, attention2 = self.decoder(trg_seq, trg_mask, enc_output, src_mask)\n",
        "\n",
        "        # ④ 최종 weight 층을 통과\n",
        "        seq_logit = self.trg_word_prj(dec_output)\n",
        "        if self.scale_prj:\n",
        "            seq_logit *= self.d_model ** -0.5\n",
        "\n",
        "        return seq_logit.view(-1, seq_logit.size(2))"
      ],
      "metadata": {
        "id": "qjbI3EPE3XhB"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0YD4P3H73Xmg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 모델 학습\n",
        "d"
      ],
      "metadata": {
        "id": "lrKYmK_IF0KK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Constants:\n",
        "    PAD_WORD = '<blank>' # padding token\n",
        "    UNK_WORD = '<unk>' # unknown token\n",
        "    BOS_WORD = '<s>' # start token\n",
        "    EOS_WORD = '</s>'\n",
        ""
      ],
      "metadata": {
        "id": "e6_Ha41dAcPf"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "src_vocab_size = len(SRC.vocab)\n",
        "trg_vocab_size= len(TRG.vocab)\n",
        "src_pad_idx = SRC.vocab.stoi[Constants.PAD_WORD]\n",
        "trg_pad_idx = TRG.vocab.stoi[Constants.PAD_WORD]\n",
        "trg_bos_idx = TRG.vocab.stoi[Constants.BOS_WORD]\n",
        "trg_eos_idx = TRG.vocab.stoi[Constants.EOS_WORD]\n",
        "d_k = 64\n",
        "d_v = 64\n",
        "d_model = 512\n",
        "d_word_vec = 512\n",
        "d_inner_hid = 2048\n",
        "n_layers = 6\n",
        "n_heads = 8\n",
        "dropout = 0.1\n",
        "proj_share_weight = True\n",
        "embs_share_weight = True\n",
        "batch_size=128\n",
        "max_lenght = 200\n"
      ],
      "metadata": {
        "id": "Z5lzZYAw-kSO"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CUDA_VISIBLE_DEVICES=-1\n",
        "transformer = Transformer(\n",
        "    src_vocab_size,\n",
        "    trg_vocab_size,\n",
        "    src_pad_idx,\n",
        "    trg_pad_idx,\n",
        "    device,\n",
        "    d_word_vec,\n",
        "    d_model,\n",
        "    d_inner_hid,\n",
        "    n_layers,\n",
        "    n_heads,\n",
        "    d_k,\n",
        "    d_v).to(device)\n",
        ""
      ],
      "metadata": {
        "id": "OqrWk5LXF0T1"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(transformer):,} trainable parameters')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3WexAHHq55Hf",
        "outputId": "03f65237-54bc-4a6d-d6ca-9d2b6d460526"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The model has 50,921,984 trainable parameters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_weights(m):\n",
        "    if hasattr(m, 'weight') and m.weight.dim() > 1:\n",
        "        nn.init.xavier_uniform_(m.weight.data)\n",
        "\n",
        "transformer.apply(initialize_weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WFf7RkAa6TGn",
        "outputId": "a415cbfa-ea05-45c9-963a-5cf0564dbb16"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Transformer(\n",
              "  (encoder): Encoder(\n",
              "    (src_word_emb): Embedding(13269, 512, padding_idx=1)\n",
              "    (position_enc): Positional_Encoding()\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "    (layer_stack): ModuleList(\n",
              "      (0-5): 6 x EncoderLayer(\n",
              "        (self_attn): MultiHeadAttention(\n",
              "          (w_q): Linear(in_features=512, out_features=512, bias=False)\n",
              "          (w_k): Linear(in_features=512, out_features=512, bias=False)\n",
              "          (w_v): Linear(in_features=512, out_features=512, bias=False)\n",
              "          (fc): Linear(in_features=512, out_features=512, bias=False)\n",
              "          (attention): ScaledDotProduct_Attention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (pos_ffn): Positionwise_FeedForward(\n",
              "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (ff_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "    )\n",
              "    (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (trg_word_emb): Embedding(13269, 512, padding_idx=1)\n",
              "    (position_enc): Positional_Encoding()\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "    (layer_stack): ModuleList(\n",
              "      (0-5): 6 x DecoderLayer(\n",
              "        (self_attn): MultiHeadAttention(\n",
              "          (w_q): Linear(in_features=512, out_features=512, bias=False)\n",
              "          (w_k): Linear(in_features=512, out_features=512, bias=False)\n",
              "          (w_v): Linear(in_features=512, out_features=512, bias=False)\n",
              "          (fc): Linear(in_features=512, out_features=512, bias=False)\n",
              "          (attention): ScaledDotProduct_Attention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (enc_attn): MultiHeadAttention(\n",
              "          (w_q): Linear(in_features=512, out_features=512, bias=False)\n",
              "          (w_k): Linear(in_features=512, out_features=512, bias=False)\n",
              "          (w_v): Linear(in_features=512, out_features=512, bias=False)\n",
              "          (fc): Linear(in_features=512, out_features=512, bias=False)\n",
              "          (attention): ScaledDotProduct_Attention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (pos_ffn): Positionwise_FeedForward(\n",
              "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (ff_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "    )\n",
              "    (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
              "  )\n",
              "  (trg_word_prj): Linear(in_features=512, out_features=13269, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5U75mrZY6TOL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ScheduledOptim():\n",
        "    '''A simple wrapper class for learning rate scheduling'''\n",
        "\n",
        "    def __init__(self, optimizer, lr_mul, d_model, n_warmup_steps):\n",
        "        self._optimizer = optimizer\n",
        "        self.lr_mul = lr_mul\n",
        "        self.d_model = d_model\n",
        "        self.n_warmup_steps = n_warmup_steps\n",
        "        self.n_steps = 0\n",
        "\n",
        "\n",
        "    def step_and_update_lr(self):\n",
        "        \"Step with the inner optimizer\"\n",
        "        self._update_learning_rate()\n",
        "        self._optimizer.step()\n",
        "\n",
        "\n",
        "    def zero_grad(self):\n",
        "        \"Zero out the gradients with the inner optimizer\"\n",
        "        self._optimizer.zero_grad()\n",
        "\n",
        "\n",
        "    def _get_lr_scale(self):\n",
        "        d_model = self.d_model\n",
        "        n_steps, n_warmup_steps = self.n_steps, self.n_warmup_steps\n",
        "        return (d_model ** -0.5) * min(n_steps ** (-0.5), n_steps * n_warmup_steps ** (-1.5))\n",
        "\n",
        "\n",
        "    def _update_learning_rate(self):\n",
        "        ''' Learning rate scheduling per step '''\n",
        "\n",
        "        self.n_steps += 1\n",
        "        lr = self.lr_mul * self._get_lr_scale()\n",
        "\n",
        "        for param_group in self._optimizer.param_groups:\n",
        "            param_group['lr'] = lr"
      ],
      "metadata": {
        "id": "cU0xpGC4j3Lj"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "n_warmup_steps = 1000\n",
        "lr_mul = 0.1\n",
        "optimizer = ScheduledOptim(\n",
        "    optim.Adam(transformer.parameters(), betas=(0.9, 0.98), eps=1e-09),\n",
        "    lr_mul, d_model, n_warmup_steps)"
      ],
      "metadata": {
        "id": "VhfZ8TJjj3Rm"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss(ignore_index=trg_pad_idx)"
      ],
      "metadata": {
        "id": "XvGl-56AdWAW"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LaBznL8xkOBH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nG94pgmRoV6e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 성능 평가"
      ],
      "metadata": {
        "id": "IFP6JcUKoXIi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 모델 성능 평가"
      ],
      "metadata": {
        "cellView": "form",
        "id": "w95-oWMSm0ZK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cal_performance(pred, gold, trg_pad_idx, smoothing=False):\n",
        "    ''' Apply label smoothing if needed '''\n",
        "\n",
        "    # loss 값을 구한다\n",
        "    loss = cal_loss(pred, gold, trg_pad_idx, smoothing=smoothing)\n",
        "\n",
        "    # 전체 단어 중에 가장 값이 높은 index 검색\n",
        "    pred = pred.max(1)[1]\n",
        "    gold = gold.contiguous().view(-1)   # 참조 레이블\n",
        "\n",
        "    # 정답지에서 padding index가 아닌거 조회\n",
        "    non_pad_mask = gold.ne(trg_pad_idx)\n",
        "\n",
        "    # 예측단어 중 정답을 맞춘거의 갯수\n",
        "    n_correct = pred.eq(gold).masked_select(non_pad_mask).sum().item()\n",
        "\n",
        "    # 정답 label 의 갯수\n",
        "    n_word = non_pad_mask.sum().item()\n",
        "\n",
        "    return loss, n_correct, n_word\n",
        "    # loss, 맞춘갯수, 전체갯수"
      ],
      "metadata": {
        "id": "V8fr8D0jGEld"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "def cal_loss(pred, gold, trg_pad_idx, smoothing=False):     # 손실 함수 계산\n",
        "    ''' Calculate cross entropy loss, apply label smoothing if needed. '''\n",
        "\n",
        "    gold = gold.contiguous().view(-1)\n",
        "\n",
        "    if smoothing:\n",
        "        eps = 0.1\n",
        "        n_class = pred.size(1)\n",
        "\n",
        "        # gold값을 pred의 shape으로 바꿔서, one-hot encoding 적용한다.\n",
        "        one_hot = torch.zeros_like(pred).scatter(1, gold.view(-1, 1), 1)\n",
        "\n",
        "        # epsilon 값에 따라 smoothing 처리한다, [0,1,0,0] → [0.03, 0.9, 0.03, 0.03]\n",
        "        one_hot = one_hot * (1 - eps) + (1 - one_hot) * eps / (n_class - 1)\n",
        "\n",
        "        # pred 값을 softmax를 이용하여 확률값으로 변환한다.\n",
        "        log_prb = F.log_softmax(pred, dim=1)\n",
        "\n",
        "        # gold에서 padding이 아닌 값의 index를 뽑는다\n",
        "        non_pad_mask = gold.ne(trg_pad_idx)\n",
        "\n",
        "        # 예측값과 smoothing된 정답값을 곱하여 loss를 산출한다.\n",
        "        loss = -(one_hot * log_prb).sum(dim=1)\n",
        "\n",
        "        # 해당 loss값에서 mask되지 않은 값을 제거하고 loss를 구한다\n",
        "        loss = loss.masked_select(non_pad_mask).sum()  # average later\n",
        "\n",
        "    else:\n",
        "        # smoothing을 사용하지 않은 경우에는 cross entropy를 사용하여 loss를 구한다.\n",
        "        loss = F.cross_entropy(pred, gold, ignore_index=trg_pad_idx, reduction='sum')\n",
        "    return loss"
      ],
      "metadata": {
        "id": "g4WB5HPBGEp2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def patch_src(src, pad_idx):\n",
        "    src = src.transpose(0, 1)\n",
        "    return src\n",
        "\n",
        "\n",
        "def patch_trg(trg, pad_idx):\n",
        "    trg = trg.transpose(0, 1)\n",
        "    trg, gold = trg[:, :-1], trg[:, 1:].contiguous().view(-1)\n",
        "    return trg, gold"
      ],
      "metadata": {
        "id": "IEz3Bwgj-5c8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch(model, traindata, optimizer, opt, device, smoothing):\n",
        "    ''' Epoch operation in training phase'''\n",
        "\n",
        "    # model.train() 학습할때 필요한 drop out, batch_normalization 등의 기능을 활성화\n",
        "    # model.eval()과 model.train()을 병행하므로, 모델 학습시에는 model.train() 호출해야함\n",
        "    model.train()\n",
        "    total_loss, n_word_total, n_word_correct = 0, 0, 0\n",
        "\n",
        "    desc = '  - (Training)   '\n",
        "    for batch in tqdm(train_data, mininterval=2, desc=desc, leave=False):\n",
        "\n",
        "        # prepare data\n",
        "        # ① src_seq. trg_seq, trg에 대한 정답 label \"gold\" 생성\n",
        "        src_seq = patch_src(batch.src, opt.src_pad_idx).to(device)\n",
        "        trg_seq, gold = map(lambda x: x.to(device), patch_trg(batch.trg, opt.trg_pad_idx))\n",
        "\n",
        "        # forward\n",
        "        # backward 전 optimizer의 기울기를 초기화해야만 새로운 가중치 편향에 대해서 새로운 기울기를 구할 수 있습니다.\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # ② model 예측값 생성\n",
        "        pred = model(src_seq, trg_seq) # 256 * (trg 문장길이-1), 10077(vocab)\n",
        "\n",
        "        # ③ loss값 계산\n",
        "        loss, n_correct, n_word = cal_performance(\n",
        "        pred, gold, opt.trg_pad_idx, smoothing=smoothing)\n",
        "\n",
        "        # ④ parameter update 진행\n",
        "        loss.backward()\n",
        "        optimizer.step_and_update_lr()\n",
        "\n",
        "        # note keeping\n",
        "        n_word_total += n_word\n",
        "        n_word_correct += n_correct\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    # 평균 loss\n",
        "    loss_per_word = total_loss/n_word_total\n",
        "\n",
        "    # 평균 acc\n",
        "    accuracy = n_word_correct/n_word_total\n",
        "\n",
        "    return loss_per_word, accuracy"
      ],
      "metadata": {
        "id": "RBVBQLfom8Uk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def eval_epoch(model, valid_data, device, opt):\n",
        "    ''' Epoch operation in evaluation phase '''\n",
        "\n",
        "    model.eval()\n",
        "    total_loss, n_word_total, n_word_correct = 0, 0, 0\n",
        "\n",
        "    desc = '  - (Validation) '\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(valid_data, mininterval=2, desc=desc, leave=False):\n",
        "\n",
        "            # prepare data\n",
        "            src_seq = patch_src(batch.src, opt.src_pad_idx).to(device)\n",
        "            trg_seq, gold = map(lambda x: x.to(device), patch_trg(batch.trg, opt.trg_pad_idx))\n",
        "\n",
        "            # forward\n",
        "            pred = model(src_seq, trg_seq)\n",
        "            loss, n_correct, n_word = cal_performance(\n",
        "                pred, gold, opt.trg_pad_idx, smoothing=False)\n",
        "\n",
        "            # note keeping\n",
        "            n_word_total += n_word\n",
        "            n_word_correct += n_correct\n",
        "            total_loss += loss.item()\n",
        "\n",
        "    loss_per_word = total_loss/n_word_total\n",
        "    accuracy = n_word_correct/n_word_total\n",
        "    return loss_per_word, accuracy"
      ],
      "metadata": {
        "id": "QSndi2Znm8W7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorboard"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0VCrNqGl-D0e",
        "outputId": "369b2ac2-074a-4d7c-fec5-37731714e054"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (2.12.3)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.56.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.4.3)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.22.4)\n",
            "Requirement already satisfied: protobuf>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (2.27.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (67.7.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (0.7.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (2.3.6)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (0.40.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (0.3.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (1.16.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard) (1.3.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import math\n",
        "import time\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "def train(model, train_data, valid_data, optimizer, device, opt):\n",
        "    ''' Start training '''\n",
        "\n",
        "    def print_performances(header, ppl, accu, start_time, lr):\n",
        "        print('  - {header:12} ppl: {ppl: 8.5f}, accuracy: {accu:3.3f} %, lr: {lr:8.5f}, '\\\n",
        "              'elapse: {elapse:3.3f} min'.format(\n",
        "                  header=f\"({header})\", ppl=ppl,\n",
        "                  accu=100*accu, elapse=(time.time()-start_time)/60, lr=lr))\n",
        "\n",
        "    #valid_accus = []\n",
        "    valid_losses = []\n",
        "    opt.epoch = 10\n",
        "    for epoch_i in range(opt.epoch):\n",
        "        print('[ Epoch', epoch_i, ']')\n",
        "\n",
        "        start = time.time()\n",
        "        opt.label_smoothing = 0.1\n",
        "        train_loss, train_accu = train_epoch(\n",
        "            model, train_data, optimizer, opt, device, smoothing=opt.label_smoothing)\n",
        "        train_ppl = math.exp(min(train_loss, 100)) # train_loss : loss_per_word, PPL = exp(cross_entropy)\n",
        "        # Current learning rate\n",
        "        lr = optimizer._optimizer.param_groups[0]['lr']\n",
        "        print_performances('Training', train_ppl, train_accu, start, lr)\n",
        "\n",
        "        start = time.time()\n",
        "        valid_loss, valid_accu = eval_epoch(model, valid_data, device, opt)\n",
        "        valid_ppl = math.exp(min(valid_loss, 100))\n",
        "        print_performances('Validation', valid_ppl, valid_accu, start, lr)\n",
        "\n",
        "        valid_losses += [valid_loss]\n",
        "\n",
        "        checkpoint = {'epoch': epoch_i, 'settings': opt, 'model': model.state_dict()}\n",
        "\n",
        "        if opt.save_mode == 'all':\n",
        "            model_name = 'model_accu_{accu:3.3f}.chkpt'.format(accu=100*valid_accu)\n",
        "            torch.save(checkpoint, model_name)\n",
        "        elif opt.save_mode == 'best':\n",
        "            model_name = 'model.chkpt'\n",
        "            if valid_loss <= min(valid_losses):\n",
        "                torch.save(checkpoint, os.path.join(opt.output_dir, model_name))\n",
        "                print('    - [Info] The checkpoint file has been updated.')"
      ],
      "metadata": {
        "id": "nqxOK2tEt27Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext.datasets import TranslationDataset\n",
        "\n",
        "def prepare_dataloaders_from_bpe_files(opt, device):\n",
        "    batch_size = opt.batch_size\n",
        "    MIN_FREQ = 2\n",
        "    if not opt.embs_share_weight:\n",
        "        raise\n",
        "\n",
        "    data = pickle.load(open(opt.data_pkl, 'rb'))\n",
        "    MAX_LEN = data['settings'].max_len\n",
        "    field = data['vocab']\n",
        "    fields = (field, field)\n",
        "\n",
        "    def filter_examples_with_length(x):\n",
        "        return len(vars(x)['src']) <= MAX_LEN and len(vars(x)['trg']) <= MAX_LEN\n",
        "\n",
        "    train = TranslationDataset(\n",
        "        fields=fields,\n",
        "        path=opt.train_path,\n",
        "        exts=('.src', '.trg'),\n",
        "        filter_pred=filter_examples_with_length)\n",
        "    val = TranslationDataset(\n",
        "        fields=fields,\n",
        "        path=opt.val_path,\n",
        "        exts=('.src', '.trg'),\n",
        "        filter_pred=filter_examples_with_length)\n",
        "\n",
        "    opt.max_token_seq_len = MAX_LEN + 2\n",
        "    opt.src_pad_idx = opt.trg_pad_idx = field.vocab.stoi[Constants.PAD_WORD]\n",
        "    opt.src_vocab_size = opt.trg_vocab_size = len(field.vocab)\n",
        "\n",
        "    train_iterator = BucketIterator(train, batch_size=batch_size, device=device, train=True)\n",
        "    val_iterator = BucketIterator(val, batch_size=batch_size, device=device)\n",
        "    return train_iterator, val_iterator\n"
      ],
      "metadata": {
        "id": "XnfDmBbvqE5X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext.data import Field, Dataset, BucketIterator\n",
        "\n",
        "def prepare_dataloaders(opt, device):\n",
        "    batch_size = opt.batch_size\n",
        "    data = pickle.load(open(opt.data_pkl, 'rb'))\n",
        "\n",
        "    opt.max_token_seq_len = data['settings'].max_len\n",
        "    opt.src_pad_idx = data['vocab']['src'].vocab.stoi[Constants.PAD_WORD]\n",
        "    opt.trg_pad_idx = data['vocab']['trg'].vocab.stoi[Constants.PAD_WORD]\n",
        "\n",
        "    opt.src_vocab_size = len(data['vocab']['src'].vocab)\n",
        "    opt.trg_vocab_size = len(data['vocab']['trg'].vocab)\n",
        "\n",
        "    if opt.embs_share_weight:\n",
        "      assert data['vocab']['src'].vocab.stoi == data['vocab']['trg'].vocab.stoi, \\\n",
        "          'To sharing word embedding the src/trg word2idx table shall be the same.'\n",
        "\n",
        "    fields = {'src': data['vocab']['src'], 'trg':data['vocab']['trg']}\n",
        "\n",
        "    train = Dataset(examples=data['train'], fields=fields)\n",
        "    val = Dataset(examples=data['valid'], fields=fields)\n",
        "\n",
        "    train_iterator = BucketIterator(train, batch_size=batch_size, device=device, train=True)\n",
        "    val_iterator = BucketIterator(val, batch_size=batch_size, device=device)\n",
        "\n",
        "    return train_iterator, val_iterator\n"
      ],
      "metadata": {
        "id": "8JGyD8XNTQ0m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kNYiUfecTQ66"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title translate task\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "nZh-9HcEqFBQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "''' Translate input text with trained model. '''\n",
        "\n",
        "import torch\n",
        "import dill as pickle\n",
        "from tqdm import tqdm\n",
        "\n",
        "def load_model(opt, device):\n",
        "\n",
        "    # load model\n",
        "    checkpoint = torch.load(opt.model, map_location=device)\n",
        "\n",
        "    # model의 option load\n",
        "    model_opt = checkpoint['settings']\n",
        "\n",
        "    # transformer model을 model option에 따라 재생성\n",
        "    model = Transformer(\n",
        "        model_opt.src_vocab_size,\n",
        "        model_opt.trg_vocab_size,\n",
        "        model_opt.src_pad_idx,\n",
        "        model_opt.trg_pad_idx,\n",
        "        trg_emb_prj_weight_sharing=model_opt.proj_share_weight,\n",
        "        emb_src_trg_weight_sharing=model_opt.embs_share_weight,\n",
        "        d_k=model_opt.d_k,\n",
        "        d_v=model_opt.d_v,\n",
        "        d_model=model_opt.d_model,\n",
        "        d_word_vec=model_opt.d_word_vec,\n",
        "        d_inner=model_opt.d_inner_hid,\n",
        "        n_layers=model_opt.n_layers,\n",
        "        n_head=model_opt.n_head,\n",
        "        dropout=model_opt.dropout).to(device)\n",
        "\n",
        "    # 학습된 weight를 model에 반영\n",
        "    model.load_state_dict(checkpoint['model'])\n",
        "    print('[Info] Trained model state loaded.')\n",
        "    return model"
      ],
      "metadata": {
        "id": "F7XHqvr7tR19"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import math\n",
        "import random\n",
        "\n",
        "model = load_model(opt, device)\n",
        "N_EPOCHS = 10\n",
        "CLIP = 1\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    start_time = time.time() # 시작 시간 기록\n",
        "\n",
        "    train_loss = train(transformer, train_data, valid_data, optimizer, device, opt)\n",
        "\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "id": "D4OGWydUMnoX",
        "outputId": "6bef3f71-9b05-4d88-fe06-7e47f100c1a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-99-882eb12ae981>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mN_EPOCHS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mCLIP\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-53-2d3c25a2d538>\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(opt, device)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# load model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# model의 option load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'EasyDict' object has no attribute 'model'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XKOdx7n9oh59"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 성능 평가 2"
      ],
      "metadata": {
        "id": "eMemIN5vojF0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, iterator, optimizer, criterion, clip):\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    for i, batch in enumerate(iterator):\n",
        "        src = batch.src\n",
        "        trg = batch.trg\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output = model(src, trg[:, :-1])\n",
        "        output_reshape = output.contiguous().view(-1, output.shape[-1])\n",
        "        trg = trg[:, 1:].contiguous().view(-1)\n",
        "\n",
        "        loss = criterion(output_reshape, trg)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "        print('step :', round((i / len(iterator)) * 100, 2), '% , loss :', loss.item())\n",
        "\n",
        "    return epoch_loss / len(iterator)"
      ],
      "metadata": {
        "id": "_u1Mi6jbopYF"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext.data.metrics import bleu_score\n",
        "candidate_corpus = [['My', 'full', 'pytorch', 'test'], ['Another', 'Sentence']]\n",
        "references_corpus = [[['My', 'full', 'pytorch', 'test'], ['Completely', 'Different']], [['No', 'Match']]]\n",
        "bleu_score(candidate_corpus, references_corpus)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YjwdTTvouDDd",
        "outputId": "7db04b01-b1b7-406c-a35f-0ffe20aab3f0"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8408964276313782"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext.data.metrics import bleu_score\n",
        "\n",
        "def evaluate(model, iterator, criterion):\n",
        "    model.eval()\n",
        "    epoch_loss = 0\n",
        "    batch_bleu = []\n",
        "    with torch.no_grad():\n",
        "        for i, batch in enumerate(iterator):\n",
        "            src = batch.src\n",
        "            trg = batch.trg\n",
        "            output = model(src, trg[:, :-1])\n",
        "            output_reshape = output.contiguous().view(-1, output.shape[-1])\n",
        "            trg = trg[:, 1:].contiguous().view(-1)\n",
        "\n",
        "            loss = criterion(output_reshape, trg)\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "            trg_words = [[TRG.target.vocab.itos[idx] for idx in trg[i].tolist()] for i in range(trg.shape[0])]\n",
        "            output_words = [[TRG.target.vocab.itos[idx] for idx in output[i].max(dim=1)[1].tolist()] for i in range(output.shape[0])]\n",
        "\n",
        "            bleu = bleu_score(output_words, trg_words)\n",
        "            batch_bleu.append(bleu)\n",
        "\n",
        "    batch_bleu = sum(batch_bleu) / len(batch_bleu)\n",
        "    return epoch_loss / len(iterator), batch_bleu"
      ],
      "metadata": {
        "id": "6m0u7jPqpYxn"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "metadata": {
        "id": "cmIWKYcFvxxY"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clip = 1.0\n",
        "import time\n",
        "\n",
        "def run(total_epoch, best_loss):\n",
        "    train_losses, test_losses, bleus = [], [], []\n",
        "    for step in range(total_epoch):\n",
        "        start_time = time.time()\n",
        "        train_loss = train(transformer, train_iterator, optimizer, criterion, clip)\n",
        "        valid_loss, bleu = evaluate(transformer, valid_iterator, criterion)\n",
        "        end_time = time.time()\n",
        "\n",
        "        if step > n_warmup_steps:\n",
        "            ScheduledOptim.step(valid_loss)\n",
        "\n",
        "        train_losses.append(train_loss)\n",
        "        test_losses.append(valid_loss)\n",
        "        bleus.append(bleu)\n",
        "        epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "        if valid_loss < best_loss:\n",
        "            best_loss = valid_loss\n",
        "            torch.save(transformer.state_dict(), 'saved/model-{0}.pt'.format(valid_loss))\n",
        "\n",
        "        f = open('result/train_loss.txt', 'w')\n",
        "        f.write(str(train_losses))\n",
        "        f.close()\n",
        "\n",
        "        f = open('result/bleu.txt', 'w')\n",
        "        f.write(str(bleus))\n",
        "        f.close()\n",
        "\n",
        "        f = open('result/test_loss.txt', 'w')\n",
        "        f.write(str(test_losses))\n",
        "        f.close()\n",
        "\n",
        "        print(f'Epoch: {step + 1} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "        print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
        "        print(f'\\tVal Loss: {valid_loss:.3f} |  Val PPL: {math.exp(valid_loss):7.3f}')\n",
        "        print(f'\\tBLEU Score: {bleu:.3f}')\n",
        ""
      ],
      "metadata": {
        "id": "_AvAYrbUpZ4m"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "factor = 0.9\n",
        "adam_eps = 5e-9\n",
        "patience = 10\n",
        "epoch = 1000\n",
        "weight_decay = 5e-4\n",
        "inf = float('inf')"
      ],
      "metadata": {
        "id": "4Ew9h2qSwfJ-"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run(total_epoch=epoch, best_loss=inf)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 378
        },
        "id": "BjU1JDwkpZ87",
        "outputId": "067c9823-097f-452c-8ce5-e17903212e61"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of q: torch.Size([24, 128, 512])\n",
            "Shape of k: torch.Size([24, 128, 512])\n",
            "Shape of v: torch.Size([24, 128, 512])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-e2cc12325eba>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-43-f88513106b3f>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(total_epoch, best_loss)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mvalid_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbleu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mend_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-39-76a74e23cd2b>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, iterator, optimizer, criterion, clip)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0moutput_reshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mtrg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-29-c5802710417c>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src_seq, trg_seq)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;31m# ② encoder 층을 통과\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0menc_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;31m# ③ decoder 층을 통과\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-25-63b9d6c76e42>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src_seq, src_mask, return_attns)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;31m# ③ stacked encoder layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0menc_layer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_stack\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0menc_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_slf_attn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menc_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menc_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m             \u001b[0menc_slf_attn_list\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0menc_slf_attn\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_attns\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-23-dd25c44ffc1c>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, enc_input, src_mask)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0menc_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_slf_attn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mself_attn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menc_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msrc_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0;31m# enc_input을 각각 q, k ,v 값으로 self-attention 수행 후 출력 텐서와 attention 가중치 텐서를 반환\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;31m# enc_input = self.self_attn_layer_norm(enc_input + self.dropout(enc_input))         # dropout, residual connection and layer norm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-21-caf931fed9cc>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, q, k, v, mask)\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# For head axis broadcasting.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m    \u001b[0;31m# 하나의 차원의 attention 값으로 출력되는 것\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;31m# Transpose to move the head dimension back: b x lq x n x dv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-20-bc90c9e28091>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, q, k, v, mask)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;31m# - 매우작은 값은 softmax를 거칠때 0과 가까운 값이 되므로 무시한다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0mattn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasked_fill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1e9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;31m# ③ soft max를 이용하여 attention weight 계산\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (128) must match the size of tensor b (8) at non-singleton dimension 3"
          ]
        }
      ]
    }
  ]
}